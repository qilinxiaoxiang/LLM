【有道云笔记】Generative AI
https://note.youdao.com/s/A2os9YLV

## 1. What
- 模型训练（Training）：从头开始训练模型。
- 预训练（Pre-Training）：在大规模数据集上训练模型。
- 微调（Fine-Tuning）：在预训练模型上进行任务特定的训练。
- 轻量化微调（Parameter Efficient Fine-Tuning, PEFT）：参数量小的微调。

## 2. Why
- 当开源模型不能满足特定业务需求时，需要通过Fine-Tuning来调整模型以适应私有部署环境。

## 3. How
### 3.1 深度学习课程推荐
- 吴恩达《人人AI》：通俗易懂。
- 李沐的深度学习课：稍微深入。

### 3.2 何时需要Fine-Tuning
- 私有部署需求。
- 开源模型能力不满足业务需求。

### 3.3 工具介绍：Hugging Face
- Hugging Face提供了模型、数据集、训练器等，方便模型下载、使用和训练。

### 3.4 模型训练流程
1. 导入相关库
2. 加载数据集
3. 加载模型
4. 加载Tokenizer
5. 处理数据集：转换成模型可接受的输入格式
6. 定义数据规整器：自动生成Batch
7. 定义训练超参：如学习率
8. 定义训练器
9. 开始训练
10. 加载训练后的模型进行推理

### 3.5 数据准备与处理
- 数据采集：自然来源、Web抓取、人造。
- 数据标注：专业标注公司、众包、主动学习。
- 数据清洗：去除不相关、冗余、误导性数据。
- 样本均衡性：保证每个标签有足够的样本，数据分布接近业务场景。
- 数据集构建：切分训练集、验证集、测试集，保证数据覆盖和分布一致性。

### 3.6 轻量化微调方法
- Prompt Tuning：在输入序列前加入伪Embedding向量，只训练这组向量。
- P-Tuning：用生成器生成伪Embedding，只有生成器参数可训练。
- Prefix-Tuning：伪造前面的Hidden States，只训练伪造的Prefix。
- LoRA：在Transformer参数矩阵上加低秩矩阵，只训练新增的矩阵。
- QLDLoRA：引入新数据类型和量化技术，节省显存。
- AdaLoRA：自适应地在参数矩阵间分配参数预算。
