{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ’¡ è¿™èŠ‚è¯¾ä¼šå¸¦ç»™ä½ \n",
    "\n",
    "1. Semantic Kernel çš„ç‰¹ç‚¹å’ŒåŸºæœ¬ç”¨æ³•\n",
    "2. äº†è§£ Semantic Kernel å†…ç½®çš„å·¥å…·\n",
    "3. å¦‚ä½•ç”¨å¥½ SDK ç®€åŒ–åŸºäº LLM çš„åº”ç”¨å¼€å‘\n",
    "\n",
    "å¼€å§‹ä¸Šè¯¾ï¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“ è¿™èŠ‚è¯¾æ€ä¹ˆå­¦\n",
    "\n",
    "ä»£ç èƒ½åŠ›è¦æ±‚ï¼š**ä¸­é«˜**ï¼ŒAI/æ•°å­¦åŸºç¡€è¦æ±‚ï¼š**æ— **\n",
    "\n",
    "1. æœ‰ç¼–ç¨‹åŸºç¡€çš„åŒå­¦\n",
    "   - å…³æ³¨è®¾è®¡æ¨¡å¼ï¼Œå®ç°ç»†èŠ‚\n",
    "2. æ²¡æœ‰ç¼–ç¨‹åŸºç¡€çš„åŒå­¦\n",
    "   - å°½é‡ç†è§£ SDK çš„æ¦‚å¿µå’Œä»·å€¼ï¼Œå°è¯•ä½“ä¼šä½¿ç”¨ SDK å‰åçš„å·®åˆ«ä¸æ„ä¹‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ã€å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼æ˜¯ä»€ä¹ˆï¼Ÿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æ‰€æœ‰å¼€å‘æ¡†æ¶ï¼ˆSDKï¼‰çš„æ ¸å¿ƒä»·å€¼ï¼Œéƒ½æ˜¯é™ä½å¼€å‘ã€ç»´æŠ¤æˆæœ¬ã€‚\n",
    "\n",
    "å¤§è¯­è¨€æ¨¡å‹å¼€å‘æ¡†æ¶çš„ä»·å€¼ï¼Œæ˜¯è®©å¼€å‘è€…å¯ä»¥æ›´æ–¹ä¾¿åœ°å¼€å‘åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚ä¸»è¦æä¾›ä¸¤ç±»å¸®åŠ©ï¼š\n",
    "\n",
    "1. ç¬¬ä¸‰æ–¹èƒ½åŠ›æŠ½è±¡ã€‚æ¯”å¦‚ LLMã€å‘é‡æ•°æ®åº“ã€æœç´¢å¼•æ“ç­‰\n",
    "2. å¸¸ç”¨å·¥å…·ã€æ–¹æ¡ˆå°è£…\n",
    "3. åº•å±‚å®ç°å°è£…ã€‚æ¯”å¦‚æµå¼æ¥å£ã€è¶…æ—¶é‡è¿ã€å¼‚æ­¥ä¸å¹¶è¡Œç­‰\n",
    "\n",
    "å¥½çš„å¼€å‘æ¡†æ¶ï¼Œéœ€è¦å…·å¤‡ä»¥ä¸‹ç‰¹ç‚¹ï¼š\n",
    "\n",
    "1. å¯é æ€§ã€é²æ£’æ€§\n",
    "2. å¯ç»´æŠ¤æ€§é«˜\n",
    "3. é«˜å†…èšã€ä½è€¦åˆ\n",
    "4. æ˜“ç”¨\n",
    "\n",
    "ä¸¾äº›é€šä¿—çš„ä¾‹å­ï¼š\n",
    "\n",
    "- ä¸å¤–éƒ¨åŠŸèƒ½è§£ä¾èµ–\n",
    "  - æ¯”å¦‚å¯ä»¥éšæ„æ›´æ¢ LLM è€Œä¸ç”¨å¤§é‡é‡æ„ä»£ç \n",
    "  - æ›´æ¢ä¸‰æ–¹å·¥å…·ä¹ŸåŒç†\n",
    "- ç»å¸¸å˜çš„éƒ¨åˆ†è¦åœ¨å¤–éƒ¨ç»´æŠ¤è€Œä¸æ˜¯æ”¾åœ¨ä»£ç é‡Œ\n",
    "  - æ¯”å¦‚ Prompt æ¨¡æ¿\n",
    "- å„ç§ç¯å¢ƒä¸‹éƒ½é€‚ç”¨\n",
    "  - æ¯”å¦‚çº¿ç¨‹å®‰å…¨\n",
    "- æ–¹ä¾¿è°ƒè¯•å’Œæµ‹è¯•\n",
    "  - è‡³å°‘è¦èƒ½æ„Ÿè§‰åˆ°ç”¨äº†æ¯”ä¸ç”¨æ–¹ä¾¿å§\n",
    "  - åˆæ³•çš„è¾“å…¥ä¸ä¼šå¼•å‘æ¡†æ¶å†…éƒ¨çš„æŠ¥é”™\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>é€‰å¯¹äº†æ¡†æ¶ï¼Œäº‹åŠåŠŸå€ï¼›åä¹‹ï¼Œäº‹å€åŠŸåŠã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ã€Semantic Kernel\n",
    "\n",
    "ã€Œ Today's AI models can easily generate messages and images for users. While this is helpful when building a simple chat app, it is not enough to build fully automated AI agents that can automate business processes and empower users to achieve more. To do so, you would need a framework that can take the responses from these models and use them to call existing code to actually do something productive. ã€\n",
    "\n",
    "1. Semantic Kernel æ˜¯å¾®è½¯ç ”å‘çš„ä¸€ä¸ªå¼€æºçš„ï¼Œé¢å‘å¤§æ¨¡å‹çš„å¼€å‘æ¡†æ¶ï¼ˆSDKï¼‰ï¼›\n",
    "2. å®ƒæ”¯æŒä½ ç”¨ä¸åŒå¼€å‘è¯­è¨€ï¼ˆC#/Python/Javaï¼‰åŸºäº OpenAI API/Azure OpenAI API/Huggingface å¼€å‘å¤§æ¨¡å‹åº”ç”¨ï¼›\n",
    "3. å®ƒå°è£…äº†ä¸€ç³»åˆ—å¼€ç®±å³ç”¨çš„å·¥å…·ï¼ŒåŒ…æ‹¬ï¼šæç¤ºè¯æ¨¡æ¿ã€é“¾å¼è°ƒç”¨ã€è§„åˆ’èƒ½åŠ›ç­‰ï¼›\n",
    "4. å®ƒå®šä½åœ¨å°†åŸºäºã€ŒPromptã€çš„ AI èƒ½åŠ›ï¼Œä¸ä¼ ç»Ÿçš„ç¨‹åºå¼€å‘æ— ç¼æ•´åˆã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_SDKï¼šSoftware Development Kitï¼Œå®ƒæ˜¯ä¸€ç»„è½¯ä»¶å·¥å…·å’Œèµ„æºçš„é›†åˆï¼Œæ—¨åœ¨å¸®åŠ©å¼€å‘è€…åˆ›å»ºã€æµ‹è¯•ã€éƒ¨ç½²å’Œç»´æŠ¤åº”ç”¨ç¨‹åºæˆ–è½¯ä»¶ã€‚_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "<b>ä»€ä¹ˆæ˜¯ SDK?</b> https://aws.amazon.com/cn/what-is/sdk/\n",
    "<br/>\n",
    "<b>SDK å’Œ API çš„åŒºåˆ«æ˜¯ä»€ä¹ˆ?</b> https://aws.amazon.com/cn/compare/the-difference-between-sdk-and-api/\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1ã€SK çš„å¼€å‘è¿›å±•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. C# ç‰ˆæœ€æˆç†Ÿï¼Œå·²å¼€å§‹ 1.10ï¼šhttps://github.com/microsoft/semantic-kernel\n",
    "2. Python æ˜¯ beta ç‰ˆï¼šhttps://github.com/microsoft/semantic-kernel\n",
    "3. Java ç‰ˆç›®å‰å•ç‹¬ç»´æŠ¤åœ¨ Java-V1åˆ†æ”¯ä¸‹ï¼šhttps://github.com/microsoft/semantic-kernel/tree/java-v1\n",
    "4. æ–‡æ¡£å†™å¾—ç‰¹åˆ«å¥½ï¼Œä½†è¿½ä¸ä¸Šä»£ç æ›´æ–°é€Ÿåº¦ï¼š\n",
    "   - æ›´å¤šè®²è§£ï¼šhttps://learn.microsoft.com/en-us/semantic-kernel/overview/\n",
    "   - æ›´åå®æ“ï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/notebooks/00-getting-started.ipynb\n",
    "   - API Reference (ç›®å‰åªæœ‰ C#): https://learn.microsoft.com/en-us/dotnet/api/microsoft.semantickernel?view=semantic-kernel-dotnet\n",
    "5. æ›´å¤šç”Ÿæ€ï¼šhttps://github.com/geffzhang/awesome-semantickernel\n",
    "\n",
    "è¿™é‡Œå¯ä»¥äº†è§£æœ€æ–°è¿›å±•ï¼šhttps://learn.microsoft.com/en-us/semantic-kernel/get-started/supported-languages\n",
    "\n",
    "ä¸åŒè¯­è¨€ä¹‹é—´çš„æ¦‚å¿µéƒ½æ˜¯ç›¸é€šçš„ã€‚æœ¬è¯¾ç¨‹ä»¥ Python ç‰ˆä¸ºä¾‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2ã€SK çš„ç”Ÿæ€ä½\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å¾®è½¯å°†æ­¤æŠ€æœ¯æ ˆå‘½åä¸º Copilot Stackã€‚ç°åœ¨å®˜æ–¹ä¹Ÿå¸¸è¯´ Agent Stackã€‚\n",
    "\n",
    "<img src=\"copilot-stack.png\" alt=\"SK çš„ç”Ÿæ€ä½\" width=\"400\"/>\n",
    "\n",
    "è§£é‡Šï¼š\n",
    "\n",
    "- Plugin extensibility: æ’ä»¶æ‰©å±•\n",
    "- Copilots: AI åŠ©æ‰‹ï¼ˆå‰¯é©¾é©¶ï¼‰ï¼Œä¾‹å¦‚ GitHub Copilotã€Office 365 Copilotã€Windows Copilot\n",
    "- AI orchestration: AI ç¼–æ’ï¼ŒSK å°±åœ¨è¿™é‡Œ\n",
    "- Foundation models: åŸºç¡€å¤§æ¨¡å‹ï¼Œä¾‹å¦‚ GPT-4\n",
    "- AI infrastructure: AI åŸºç¡€è®¾æ–½ï¼Œä¾‹å¦‚ PyTorchã€GPU\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### æ€ä¹ˆç†è§£è¿™ä¸ª **AI ç¼–æ’**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK æ˜¯ä¸ªé‡å¿ƒå‹ƒå‹ƒçš„é¡¹ç›®ï¼Œå®ƒå¸Œæœ›ï¼š\n",
    "\n",
    "1. è®©å¼€å‘è€…æ›´å®¹æ˜“çš„æŠŠ LLM çš„èƒ½åŠ›é›†æˆåˆ°åº”ç”¨ä¸­ï¼Œåƒè°ƒç”¨å‡½æ•°ä¸€æ ·ç®€å•\n",
    "2. è®© Prompt æ„æˆçš„ã€Œå‡½æ•°ã€ï¼ˆSemantic Functionï¼Œè§ä¸‹æ–‡ï¼‰ä¸åŸç”Ÿå‡½æ•°ä¹‹é—´ï¼Œå¯ä»¥å¾ˆæ–¹ä¾¿çš„äº’ç›¸åµŒå¥—è°ƒç”¨\n",
    "3. è®© AI è‡ªåŠ¨è°ƒç”¨æœ¬åœ°å‡½æ•°ï¼ˆNative Functionï¼‰æ‰§è¡Œç›¸åº”åŠŸèƒ½æˆ–æ“ä½œ\n",
    "4. è®©å¼€å‘è€…å¼€å‘çš„ LLM èƒ½åŠ›ä¸åº”ç”¨è§£è€¦ï¼Œé«˜åº¦å¯å¤ç”¨\n",
    "5. è®©å¼€å‘è€…èƒ½ä¸å¾®è½¯çš„æ•´ä¸ª Copilot ç”Ÿæ€ç´§å¯†ç»“åˆï¼Œäº’ç›¸æä¾›å…»æ–™\n",
    "\n",
    "è¯·å¸¦ç€è¿™ä¸ªè§†è§’ï¼Œé€æ­¥ä½“ä¼šåé¢æ‰€è®²çš„çŸ¥è¯†ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>ä½¿ç”¨ SK çš„ä½œä¸º AI ç¼–æ’å™¨çš„æ¡ˆä¾‹ï¼š</b> <a href=\"https://github.com/Azure-Samples/miyagi\">https://github.com/Azure-Samples/miyagi</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3ã€SK åŸºç¡€æ¶æ„\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"mind-and-body-of-semantic-kernel.png\" alt=\"SK çš„æ¶æ„\" width=\"400\"/>\n",
    "\n",
    "è§£é‡Šï¼š\n",
    "\n",
    "- Models and Memory: ç±»æ¯”ä¸ºå¤§è„‘\n",
    "- Connectors: ç”¨æ¥è¿æ¥å„ç§å¤–éƒ¨æœåŠ¡ï¼Œç±»ä¼¼é©±åŠ¨ç¨‹åº\n",
    "- Plugins: ç”¨æ¥è¿æ¥å†…éƒ¨æŠ€èƒ½\n",
    "- Triggers and actions: å¤–éƒ¨ç³»ç»Ÿçš„è§¦å‘å™¨å’ŒåŠ¨ä½œï¼Œç±»æ¯”ä¸ºå››è‚¢\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ç±»æ¯”ï¼š** Semantic Kernel ç”¨ **Kernel** å‘½åï¼Œæ˜¯å› ä¸ºå®ƒç¡®å®åƒä¸ªæ“ä½œç³»ç»Ÿ kernelï¼Œåšæ ¸å¿ƒèµ„æºè°ƒé…ï¼Œå„ç§èµ„æºéƒ½å¯ä»¥æŒ‚åœ¨å®ƒä¸Šã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**è¯´æ˜ï¼š** Sematic Kernel é€šè¿‡ **Kernel** é“¾æ¥ LLM ä¸ **Functions**ï¼ˆåŠŸèƒ½ï¼‰:\n",
    "\n",
    "- Semantic Functionsï¼šé€šè¿‡ Prompt å®ç°çš„ LLM èƒ½åŠ›\n",
    "- Native Functions: ç¼–ç¨‹è¯­è¨€åŸç”Ÿçš„å‡½æ•°åŠŸèƒ½\n",
    "\n",
    "åœ¨ SK ä¸­ï¼Œä¸€ç»„ Function ç»„æˆä¸€ä¸ªæŠ€èƒ½ï¼ˆSkill/Pluginï¼‰ã€‚è¦è¿è¡Œ Skill/Pluginï¼Œéœ€è¦æœ‰ä¸€ä¸ªé…ç½®å’Œç®¡ç†çš„å•å…ƒï¼Œè¿™ä¸ªç»„ç»‡ç®¡ç†å•å…ƒå°±æ˜¯ Kernelã€‚\n",
    "\n",
    "Kernel è´Ÿè´£ç®¡ç†åº•å±‚æ¥å£ä¸è°ƒç”¨é¡ºåºï¼Œä¾‹å¦‚ï¼šOpenAI/Azure OpenAI çš„æˆæƒä¿¡æ¯ã€é»˜è®¤çš„ LLM æ¨¡å‹é€‰æ‹©ã€å¯¹è¯ä¸Šä¸‹æ–‡ã€æŠ€èƒ½å‚æ•°çš„ä¼ é€’ç­‰ç­‰ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ã€ç¯å¢ƒæ­å»º\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. å®‰è£… Python 3.xï¼šhttps://www.python.org/downloads/\n",
    "2. å®‰è£… SK åŒ…ï¼š`pip install semantic-kernel`\n",
    "3. åœ¨é¡¹ç›®ç›®å½•åˆ›å»º .env æ–‡ä»¶ï¼Œæ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š\n",
    "\n",
    "```bash\n",
    "# .env\n",
    "OPENAI_API_KEY=\"\"\n",
    "OPENAI_BASE_URL=\"\"\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME=\"\"\n",
    "AZURE_OPENAI_ENDPOINT=\"\"\n",
    "AZURE_OPENAI_API_KEY=\"\"\n",
    "```\n",
    "\n",
    "OpenAI å’Œ Azureï¼Œé…ç½®å¥½ä¸€ä¸ªå°±è¡Œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade semantic-kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --upgrade pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1ã€Hello, World!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™æ˜¯ä¸€ä¸ªç®€å•ç¤ºä¾‹ã€‚\n",
    "\n",
    "ç¬¬ä¸€æ®µä»£ç æ˜¯åˆå§‹åŒ–ã€‚åé¢æ‰€æœ‰ä»£ç éƒ½è¦åœ¨æ‰§è¡Œè¿‡è¿™æ®µä»£ç åï¼Œæ‰èƒ½æ‰§è¡Œã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "\n",
    "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# åˆ›å»º semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# é…ç½® OpenAI æœåŠ¡ã€‚OPENAI_BASE_URL ä¼šè¢«è‡ªåŠ¨åŠ è½½ç”Ÿæ•ˆ\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "\n",
    "# å°† LLM æœåŠ¡æ·»åŠ åˆ° kernel ä¸­\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=service_id, \n",
    "        ai_model_id=\"gpt-3.5-turbo-1106\", \n",
    "        api_key=api_key\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt è°ƒç”¨å¤§æ¨¡å‹ï¼Œè¢«å½“åšä¸€ä¸ª **Semantic Function** ï¼ˆä¸‹æ–‡è¯¦è¿°ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸ºä»€ä¹ˆçŒ«å’ªä¸å–œæ¬¢æ‰“æ‰‘å…‹ç‰Œï¼Ÿ\n",
      "å› ä¸ºä»–ä»¬æ€»æ˜¯è¢«æŠ“ä½ï¼\n"
     ]
    }
   ],
   "source": [
    "# å®šä¹‰ semantic function\n",
    "\n",
    "joke_function = kernel.add_function(\n",
    "    function_name=\"joke\", # function åå­—ï¼Œå¿…å¡«\n",
    "    plugin_name=\"MyDemoPlugin\", # function æ‰€å±çš„ pluginï¼Œå¿…å¡«\n",
    "    prompt=\"è®²ä¸ªç¬‘è¯\" # promptï¼Œå¿…å¡«\n",
    ")\n",
    "\n",
    "# è¿è¡Œ function çœ‹ç»“æœ\n",
    "result = await kernel.invoke(joke_function)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ³¨æ„**ï¼šä»¥ä¸Šä»£ç æ˜¯åœ¨ Jupyter ç¬”è®°è¿è¡Œçš„å½¢å¼ï¼Œå¦‚æœæœ¬åœ°è¿è¡Œï¼Œè¯·å‚è€ƒä»¥ä¸‹å½¢å¼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import asyncio\n",
    "\n",
    "async def run_function(*args):\n",
    "    return await kernel.invoke(*args)\n",
    "\n",
    "result = asyncio.run(\n",
    "    run_function(joke_function)\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>åˆ’é‡ç‚¹ï¼š</b>\n",
    "ç”¨æˆ‘ä»¬ç†Ÿæ‚‰çš„æ“ä½œç³»ç»Ÿæ¥ç±»æ¯”ï¼Œå¯ä»¥æ›´å¥½åœ°ç†è§£ SKã€‚\n",
    "<ol>\n",
    "<li>å¯åŠ¨æ“ä½œç³»ç»Ÿï¼š<code>kernel = sk.Kernel()</code></li>\n",
    "<li>å®‰è£…é©±åŠ¨ç¨‹åºï¼š<code>kernel.add_service()</code></li>\n",
    "<li>å®‰è£…åº”ç”¨ç¨‹åºï¼š<code>func = kernel.add_function()</code></li>\n",
    "<li>è¿è¡Œåº”ç”¨ç¨‹åºï¼š<code>kernel.invoke(func...)</code></li>\n",
    "</ol>\n",
    "</div>\n",
    "\n",
    "åŸºäº SK å¼€å‘çš„ä¸»è¦å·¥ä½œæ˜¯å†™ã€Œåº”ç”¨ç¨‹åºã€ï¼Œä¹Ÿå°±æ˜¯ Pluginsï¼ˆè§ä¸‹æ–‡ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2ã€Prompt æ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "# è·å–å½“å‰é»˜è®¤è®¾å®š\n",
    "req_settings = kernel.get_service(service_id).get_prompt_execution_settings_class()(service_id=service_id)\n",
    "\n",
    "# å®šä¹‰ Prompt æ¨¡æ¿ \n",
    "# æ¨¡æ¿ä¸­ï¼Œå˜é‡ä»¥ {{$å˜é‡å}} è¡¨ç¤º\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=\"è®²ä¸ªå…³äº{{$topic}}çš„ç¬‘è¯\",\n",
    "    description=\"Generate a joke about a specific topic\",\n",
    "    execution_settings={service_id: req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"topic\", description=\"The topic\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# æ³¨å†Œ function\n",
    "topical_joke_function = kernel.add_function(\n",
    "    function_name=\"topical_joke\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°æ˜å»å‚åŠ ä¸€ä¸ªé¢è¯•ï¼Œé¢è¯•å®˜é—®ä»–ï¼šâ€œä½ æœ‰ä»€ä¹ˆç‰¹é•¿å—ï¼Ÿâ€\n",
      "å°æ˜è¯´ï¼šâ€œæˆ‘æœ‰ä¸€ä¸ªç‰¹åˆ«å‰å®³çš„ç‰¹é•¿ã€‚â€\n",
      "é¢è¯•å®˜å¥½å¥‡åœ°é—®ï¼šâ€œæ˜¯ä»€ä¹ˆç‰¹é•¿ï¼Ÿâ€\n",
      "å°æ˜ç­”é“ï¼šâ€œæˆ‘ç‰¹åˆ«æ“…é•¿ç¡è§‰ï¼Œæ— è®ºä»€ä¹ˆæ—¶å€™éƒ½èƒ½ç¡å¾—å¾ˆé¦™ã€‚â€\n",
      "é¢è¯•å®˜ç¬‘äº†ç¬‘è¯´ï¼šâ€œè¿™å¯ä¸æ˜¯ä¸€ä¸ªå¥½çš„ç‰¹é•¿å•Šã€‚â€\n",
      "å°æ˜ç«‹åˆ»å›ç­”ï¼šâ€œä½†æ˜¯æˆ‘å¯ä»¥åœ¨å·¥ä½œä¸­ä¿æŒé«˜æ•ˆç‡ï¼Œå› ä¸ºæˆ‘ç¡å¾—å¾ˆé¦™ï¼Œç²¾åŠ›å……æ²›ï¼â€\n"
     ]
    }
   ],
   "source": [
    "# è¿è¡Œ function çœ‹ç»“æœ\n",
    "result = await kernel.invoke(\n",
    "    topical_joke_function, \n",
    "    KernelArguments(topic=\"å°æ˜\") # ä¼ å…¥å‚æ•°\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3ã€Semantic Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Functions æ˜¯çº¯ç”¨æ•°æ®ï¼ˆPrompt + é…ç½®ï¼‰å®šä¹‰çš„ï¼Œä¸éœ€è¦ç¼–å†™ä»»ä½•ä»£ç ã€‚æ‰€ä»¥å®ƒä¸ç¼–ç¨‹è¯­è¨€æ— å…³ï¼Œå¯ä»¥è¢«ä»»ä½•ç¼–ç¨‹è¯­è¨€è°ƒç”¨ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1ã€æŒä¹…åŒ–å­˜å‚¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥å°† semantic function ä¸æºä»£ç åˆ†ç¦»å­˜å‚¨ã€‚è¿™æ ·æ›´æ˜“äºç»´æŠ¤ä¸å¤ç”¨ã€‚\n",
    "\n",
    "ä¸€ä¸ªå…¸å‹çš„ semantic function åŒ…å«ä¸¤ä¸ªæ–‡ä»¶ï¼š\n",
    "\n",
    "- skprompt.txt: å­˜æ”¾ promptï¼Œå¯ä»¥åŒ…å«å‚æ•°ï¼Œè¿˜å¯ä»¥è°ƒç”¨å…¶å®ƒå‡½æ•°\n",
    "- config.json: å­˜æ”¾é…ç½®ï¼ŒåŒ…æ‹¬å‡½æ•°åŠŸèƒ½ï¼Œå‚æ•°çš„æ•°æ®ç±»å‹ï¼Œä»¥åŠè°ƒç”¨å¤§æ¨¡å‹æ—¶çš„å‚æ•°\n",
    "\n",
    "ä¸¾ä¾‹ï¼šæ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€æŒ‡ç¤ºï¼Œç”Ÿæˆ SQL æŸ¥è¯¢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skprompt.txt\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "å·²çŸ¥æ•°æ®åº“ç»“æ„ä¸ºï¼š\n",
    "```\n",
    "CREATE TABLE Courses (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    course_date DATE NOT NULL,\n",
    "    start_time TIME NOT NULL,\n",
    "    end_time TIME NOT NULL,\n",
    "    course_name VARCHAR(255) NOT NULL,\n",
    "    instructor VARCHAR(255) NOT NULL\n",
    ");\n",
    "```\n",
    "è¯·å°†ä¸‹è¿°ç”¨æˆ·è¾“å…¥è½¬ä¸ºSQLè¡¨è¾¾å¼\n",
    "ç”¨æˆ·è¾“å…¥ï¼š{{$input}}\n",
    "\n",
    "ç›´æ¥è¾“å‡ºSQLè¯­å¥ï¼Œä¸è¦è¯„è®ºï¼Œä¸è¦åˆ†æï¼Œä¸è¦Markdownæ ‡è¯†!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config.json\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "{\n",
    "    \"schema\": 1,\n",
    "    \"type\": \"completion\",\n",
    "    \"description\": \"å°†ç”¨æˆ·çš„è¾“å…¥è½¬æ¢æˆ SQL è¯­å¥\",\n",
    "    \"completion\": {\n",
    "        \"max_tokens\": 256,\n",
    "        \"temperature\": 0,\n",
    "        \"top_p\": 0,\n",
    "        \"presence_penalty\": 0,\n",
    "        \"frequency_penalty\": 0\n",
    "    },\n",
    "    \"input\": {\n",
    "        \"parameters\": [\n",
    "            {\n",
    "                \"name\": \"input\",\n",
    "                \"description\": \"ç”¨æˆ·çš„è¾“å…¥\",\n",
    "                \"defaultValue\": \"\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¯´æ˜ï¼š\n",
    "\n",
    "- `type` åªæœ‰ `\"completion\"` å’Œ `\"embedding\"` ä¸¤ç§\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢ä¸¤ä¸ªæ–‡ä»¶éƒ½åœ¨ [demo/MyPlugins/Text2SQL/](demo/MyPlugins/Text2SQL/) ç›®å½•ä¸‹ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2ã€å¯¼å…¥ Semantic Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM Courses WHERE course_date BETWEEN '2024-04-01' AND '2024-04-30';\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½ semantic functionã€‚æ³¨æ„ç›®å½•ç»“æ„\n",
    "my_plugins = kernel.add_plugin(parent_directory=\"./demo\", plugin_name=\"MyPlugins\")\n",
    "\n",
    "func = my_plugins[\"Text2SQL\"]\n",
    "\n",
    "# è¿è¡Œ\n",
    "result = await kernel.invoke(\n",
    "    func,\n",
    "    KernelArguments(input=\"2024å¹´4æœˆæœ‰å“ªäº›è¯¾\") ,\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4ã€å¤šä¸ªè¾“å…¥å˜é‡"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¾‹å¦‚æˆ‘ä»¬è¦ç»´æŠ¤ä¸€ä¸ªå¤šè½®å¯¹è¯ï¼Œé€šè¿‡ request å’Œ history ä¸¤ä¸ªå˜é‡åˆ†åˆ«å­˜å‚¨ å½“å‰è¾“å…¥ å’Œ å¯¹è¯å†å²\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"å¯¹è¯å†å²å¦‚ä¸‹:\n",
    "{{$history}}\n",
    "---\n",
    "User: {{$request}}\n",
    "Assistant:  \"\"\"\n",
    "\n",
    "# å®šä¹‰ Prompt æ¨¡æ¿ \n",
    "# æ¨¡æ¿ä¸­ï¼Œå˜é‡ä»¥ {{$å˜é‡å}} è¡¨ç¤º\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    description=\"Multi-turn dialogue\",\n",
    "    execution_settings={service_id: req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"request\", description=\"The user input\", is_required=True),\n",
    "        InputVariable(name=\"history\", description=\"The dialogue history\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# æ³¨å†Œ function\n",
    "chat = kernel.add_function(\n",
    "    function_name=\"chat\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>æ³¨æ„ï¼š</b>å®é™…å¼€å‘ä¸­ï¼Œå°† Prompt æ¨¡æ¿ä»¥æ–‡ä»¶å½¢å¼å­˜å‚¨æ›´å®¹æ˜“ç»´æŠ¤ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User >  æˆ‘å«ç‹å“ç„¶\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > ä½ å¥½ï¼Œç‹å“ç„¶å…ˆç”Ÿï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User >  æˆ‘å«ä»€ä¹ˆåå­—\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > ä½ çš„åå­—æ˜¯ç‹å“ç„¶ã€‚\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User >  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User >  æˆ‘æ˜¯è°\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant > ä½ æ˜¯ç‹å“ç„¶ã€‚æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User >  \n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.contents import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\"You are a helpful chatbot who is good at answering user's questions.\")\n",
    "\n",
    "while True:\n",
    "    request = input(\"User > \").strip()\n",
    "    if not request:\n",
    "        break\n",
    "    result = await kernel.invoke(\n",
    "        chat,\n",
    "        KernelArguments(\n",
    "            request=request,\n",
    "            history=chat_history\n",
    "        ),\n",
    "    )\n",
    "    print(f\"Assistant > {result}\")\n",
    "    chat_history.add_user_message(request)\n",
    "    chat_history.add_assistant_message(str(result))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5ã€Native Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”¨ç¼–ç¨‹è¯­è¨€å†™çš„å‡½æ•°ï¼Œå¦‚æœç”¨ SK çš„ Native Function æ–¹å¼å®šä¹‰ï¼Œå°±èƒ½çº³å…¥åˆ° SK çš„ç¼–æ’ä½“ç³»ï¼Œå¯ä»¥è¢« Plannerã€å…¶å®ƒ Plugin è°ƒç”¨ã€‚\n",
    "\n",
    "ä¸‹é¢ï¼Œå†™ä¸€ä¸ªæŸ¥è¯¢æ•°æ®åº“çš„å‡½æ•°ã€‚\n",
    "\n",
    "è¿™ä¸ªå‡½æ•°åæ˜¯ `query_database`ã€‚è¾“å…¥ä¸ºä¸€ä¸ª SQL è¡¨è¾¾å¼\n",
    "\n",
    "å®ƒå¯ä»¥æ”¾åˆ°ç›®å½•ç»“æ„ä¸­ï¼Œåœ¨ [demo/MyPlugins/DBPlugin.py](demo/MyPlugins/DBPlugin.py) é‡ŒåŠ å…¥ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.functions import kernel_function\n",
    "\n",
    "class DBConnectorPlugin:\n",
    "    def __init__(self, db_cursor):\n",
    "        self.db_cursor = db_cursor\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"æŸ¥è¯¢æ•°æ®åº“\",  # function æè¿°\n",
    "        name=\"query_database\",  # function åå­—\n",
    "    )\n",
    "    def exec(self, sql_exp: str) -> str:\n",
    "        self.db_cursor.execute(sql_exp)\n",
    "        records = cursor.fetchall()\n",
    "        return str(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æœ¬åœ°å‡½æ•°å’Œæ•°æ®åº“\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# åˆ›å»ºæ•°æ®åº“è¿æ¥\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# åˆ›å»ºordersè¡¨\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE Courses (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    course_date DATE NOT NULL,\n",
    "    start_time TIME NOT NULL,\n",
    "    end_time TIME NOT NULL,\n",
    "    course_name VARCHAR(255) NOT NULL,\n",
    "    instructor VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# æ’å…¥5æ¡æ˜ç¡®çš„æ¨¡æ‹Ÿè®°å½•\n",
    "timetable = [\n",
    "    ('2024-01-23', '20:00', '22:00', 'å¤§æ¨¡å‹åº”ç”¨å¼€å‘åŸºç¡€', 'å­™å¿—å²—'),\n",
    "    ('2024-01-25', '20:00', '22:00', 'Prompt Engineering', 'å­™å¿—å²—'),\n",
    "    ('2024-01-29', '20:00', '22:00', 'èµ è¯¾ï¼šè½¯ä»¶å¼€å‘åŸºç¡€æ¦‚å¿µä¸ç¯å¢ƒæ­å»º', 'è¥¿æ ‘'),\n",
    "    ('2024-02-20', '20:00', '22:00', 'ä»AIç¼–ç¨‹è®¤çŸ¥AI', 'æ—æ™“é‘«'),\n",
    "    ('2024-02-22', '20:00', '22:00', 'Function Calling', 'å­™å¿—å²—'),\n",
    "    ('2024-02-29', '20:00', '22:00', 'RAGå’ŒEmbeddings', 'ç‹å“ç„¶'),\n",
    "    ('2024-03-05', '20:00', '22:00', 'Assistants API', 'ç‹å“ç„¶'),\n",
    "    ('2024-03-07', '20:00', '22:00', 'Semantic Kernel', 'ç‹å“ç„¶'),\n",
    "    ('2024-03-14', '20:00', '22:00', 'LangChain', 'ç‹å“ç„¶'),\n",
    "    ('2024-03-19', '20:00', '22:00', 'LLMåº”ç”¨å¼€å‘å·¥å…·é“¾', 'ç‹å“ç„¶'),\n",
    "    ('2024-03-21', '20:00', '22:00', 'æ‰‹æ’• AutoGPT', 'ç‹å“ç„¶'),\n",
    "    ('2024-03-26', '20:00', '22:00', 'æ¨¡å‹å¾®è°ƒï¼ˆä¸Šï¼‰', 'ç‹å“ç„¶'),\n",
    "    ('2024-03-28', '20:00', '22:00', 'æ¨¡å‹å¾®è°ƒï¼ˆä¸‹ï¼‰', 'ç‹å“ç„¶'),\n",
    "    ('2024-04-09', '20:00', '22:00', 'å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆä¸Šï¼‰', 'å¤šè€å¸ˆ'),\n",
    "    ('2024-04-11', '20:00', '22:00', 'å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆä¸­ï¼‰', 'å¤šè€å¸ˆ'),\n",
    "    ('2024-04-16', '20:00', '22:00', 'å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼ˆä¸‹ï¼‰', 'å¤šè€å¸ˆ'),\n",
    "    ('2024-04-18', '20:00', '22:00', 'AIäº§å“éƒ¨ç½²å’Œäº¤ä»˜ï¼ˆä¸Šï¼‰', 'ç‹æ ‘å†¬'),\n",
    "    ('2024-04-23', '20:00', '22:00', 'AIäº§å“éƒ¨ç½²å’Œäº¤ä»˜ï¼ˆä¸‹ï¼‰', 'ç‹æ ‘å†¬'),\n",
    "    ('2024-04-25', '20:00', '22:00', 'æŠ“ä½å¤§æ¨¡å‹æ—¶ä»£çš„åˆ›ä¸šæœºé‡', 'å­™å¿—å²—'),\n",
    "    ('2024-05-07', '20:00', '22:00', 'äº§å“è¿è¥å’Œä¸šåŠ¡æ²Ÿé€š', 'å­™å¿—å²—'),\n",
    "    ('2024-05-09', '20:00', '22:00', 'äº§å“è®¾è®¡', 'å­™å¿—å²—'),\n",
    "    ('2024-05-14', '20:00', '22:00', 'é¡¹ç›®æ–¹æ¡ˆåˆ†æä¸è®¾è®¡', 'ç‹å“ç„¶'),\n",
    "]\n",
    "\n",
    "for record in timetable:\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Courses (course_date, start_time, end_time, course_name, instructor)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', record)\n",
    "\n",
    "# æäº¤äº‹åŠ¡\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9,)]\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½ native function\n",
    "db_connector = kernel.add_plugin(DBConnectorPlugin(cursor), \"DBConnectorPlugin\")\n",
    "\n",
    "# çœ‹ç»“æœ\n",
    "result = await kernel.invoke(\n",
    "    db_connector[\"query_database\"],\n",
    "    KernelArguments(\n",
    "        sql_exp=\"SELECT COUNT(*) as count FROM Courses WHERE instructor = 'ç‹å“ç„¶'\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "åœ¨ SK ä¸­ï¼ŒSemantic Function å’Œ Native Function è¢« Kernel å¹³ç­‰å¯¹å¾…ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**æ³¨æ„**: å¦ä¸€ç§ native function çš„è°ƒç”¨æ–¹æ³•ï¼Œå¯ä»¥å†™æˆä¸‹è¿°å½¢å¼ã€‚ä½†ä¸Šé¢çš„å½¢å¼æ›´ç¬¦åˆ SK çš„è®¾è®¡ç†å¿µã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(9,)]\n"
     ]
    }
   ],
   "source": [
    "result = await db_connector[\"query_database\"](\n",
    "    kernel, sql_exp=\"SELECT COUNT(*) as count FROM Courses WHERE instructor = 'ç‹å“ç„¶'\"\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1ã€å‡½æ•°å‚æ•° Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥é€šè¿‡ Python çš„ typing åº“ä¸­çš„ Annotated å¯¹è±¡æ ‡è¯†æ¯ä¸ªå‚æ•°çš„ç±»å‹å’Œå«ä¹‰ï¼Œä»¥ä¾¿æœªæ¥åœ¨ agent ä¸­ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from typing import Annotated\n",
    "\n",
    "class DBConnectorPlugin:\n",
    "    def __init__(self, db_cursor):\n",
    "        self.db_cursor = db_cursor\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"æŸ¥è¯¢æ•°æ®åº“\",  # function æè¿°\n",
    "        name=\"query_database\",  # function åå­—\n",
    "    )\n",
    "    def exec(\n",
    "            self, \n",
    "            sql_exp: Annotated[str, \"SQLæŸ¥è¯¢è¡¨è¾¾å¼\"]\n",
    "        ) -> Annotated[str, \"æ•°æ®åº“æŸ¥è¯¢ç»“æœ\"]:\n",
    "        self.db_cursor.execute(sql_exp)\n",
    "        records = cursor.fetchall()\n",
    "        return str(records)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6ã€Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç®€å•è¯´ï¼Œplugin å°±æ˜¯ä¸€ç»„å‡½æ•°çš„é›†åˆã€‚ä¹Ÿå¯ä»¥ç†è§£ä¸º namespaceã€‚å®ƒå¯ä»¥åŒ…å«ä¸¤ç§å‡½æ•°ï¼š\n",
    "\n",
    "- Semantic Functions - è¯­ä¹‰å‡½æ•°ï¼Œæœ¬è´¨æ˜¯ Prompt Engineering\n",
    "- Native Functions - åŸç”Ÿå‡½æ•°ï¼Œå°†æœ¬åœ°ä»£ç åŠŸèƒ½æ³¨å†Œåœ¨ Kernel ä¸­\n",
    "\n",
    "å€¼å¾—ä¸€æçš„æ˜¯ï¼ŒSK çš„ plugin ä¼šå’Œ ChatGPTã€Bingã€Microsoft 365 é€šç”¨ã€‚ã€Œå¾ˆå¿«ã€ä½ ç”¨ SK å†™çš„ plugin å°±å¯ä»¥åœ¨è¿™äº›å¹³å°ä¸Šæ— ç¼ä½¿ç”¨äº†ã€‚è¿™äº›å¹³å°ä¸Šçš„ plugin ä¹Ÿå¯ä»¥é€šè¿‡ SK è¢«ä½ è°ƒç”¨ã€‚\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>æ³¨æ„ï¼š</b>Plugins æœ€åˆå‘½åä¸º Skillsï¼Œåæ¥æ”¹ä¸º Pluginsã€‚å¦‚æœæ–‡æ¡£ä¸­è¿˜æœ‰ã€ŒSkillã€é—ç•™ã€‚è§åˆ°åï¼Œå°±çŸ¥é“ä¸¤è€…æ˜¯ä¸€å›äº‹å°±å¥½ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å›é¡¾å¾®è½¯çš„è®¾è®¡ç†å¿µï¼šåº”ç”¨é€šè¿‡ SK è°ƒç”¨ Plugins å®Œæˆå„ç§ä»»åŠ¡\n",
    "\n",
    "<img src=\"cross-platform-plugins.png\" width=600px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6.1ã€å†…ç½® Plugins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK å†…ç½®äº†è‹¥å¹²å¥½ç”¨çš„ plugin\n",
    "\n",
    "åŠ è½½æ–¹æ³•ï¼š\n",
    "\n",
    "```python\n",
    "from semantic_kernel.core_plugins import <PluginName>\n",
    "```\n",
    "\n",
    "å®ƒä»¬æ˜¯ï¼š\n",
    "\n",
    "- [`ConversationSummaryPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/conversation_summary_plugin.py) - ç”Ÿæˆå¯¹è¯çš„æ‘˜è¦\n",
    "- [`HttpPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/http_plugin.py) - å‘å‡º HTTP è¯·æ±‚ï¼Œæ”¯æŒ GETã€POSTã€PUT å’Œ DELETE\n",
    "- [`MathPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/math_plugin.py) - åŠ æ³•å’Œå‡æ³•è®¡ç®—\n",
    "- [`TextMemoryPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/text_memory_plugin.py) - ä¿å­˜æ–‡æœ¬åˆ° memory ä¸­ï¼Œå¯ä»¥å¯¹å…¶åšå‘é‡æ£€ç´¢\n",
    "- [`TextPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/text_plugin.py) - æŠŠæ–‡æœ¬å…¨éƒ¨è½¬ä¸ºå¤§å†™æˆ–å°å†™ï¼Œå»æ‰å¤´å°¾çš„ç©ºæ ¼ï¼ˆtrimï¼‰\n",
    "- [`TimePlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/time_plugin.py) - è·å–å½“å‰æ—¶é—´åŠç”¨å¤šç§æ ¼å¼è·å–æ—¶é—´å‚æ•°\n",
    "- [`WaitPlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/wait_plugin.py) - ç­‰å¾…æŒ‡å®šçš„æ—¶é—´\n",
    "- [`WebSearchEnginePlugin`](https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/core_plugins/web_search_engine_plugin.py) - åœ¨äº’è”ç½‘ä¸Šæœç´¢ç»™å®šçš„æ–‡æœ¬\n",
    "  ) - åœ¨äº’è”ç½‘ä¸Šæœç´¢ç»™å®šçš„æ–‡æœ¬\n",
    "  osoft/semantic-kernel/blob/main/python/semantic_kernel/core_skills/web_search_engine_skill.py) - åœ¨äº’è”ç½‘ä¸Šæœç´¢ç»™å®šçš„æ–‡æœ¬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ã€å‡½æ•°çš„åµŒå¥—è°ƒç”¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1ã€Semantic Function åµŒå¥—è°ƒç”¨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK å…è®¸åœ¨ Prompt æ¨¡æ¿ä¸­ç›´æ¥è°ƒç”¨ä¸€ä¸ªå‡½æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate_prompt = \"\"\"\n",
    "å°†ä¸­æ–‡è¯'{{$chinese}}'ç¿»è¯‘ä¸ºæ—¥è¯­\n",
    "ç›´æ¥ç»™å‡ºä¸€ä¸ªç¿»è¯‘ç»“æœï¼Œä¸è¦è¯„è®ºã€‚\n",
    "å°½å¯èƒ½ç”¨Hanjiè¡¨ç¤ºã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_prompt = \"\"\"\n",
    "'{{$input}}'çš„æ—¥è¯­æ˜¯ï¼š{{MyDemoPlugin.translate $input}}\n",
    "æ ¹æ®ä»¥ä¸Šè¯æ±‡åœ¨ä¸­æ—¥æ–‡ä¸­çš„è¯­ä¹‰å·®å¼‚ï¼Œè®²ä¸€ä¸ªç¬‘è¯ã€‚\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "\n",
    "\n",
    "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# åˆ›å»º semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# é…ç½® OpenAI æœåŠ¡ã€‚OPENAI_BASE_URL ä¼šè¢«è‡ªåŠ¨åŠ è½½ç”Ÿæ•ˆ\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "\n",
    "# å°† LLM æœåŠ¡æ·»åŠ åˆ° kernel ä¸­\n",
    "kernel.add_service(\n",
    "    OpenAIChatCompletion(\n",
    "        service_id=service_id, \n",
    "        ai_model_id=\"gpt-3.5-turbo-1106\", \n",
    "        api_key=api_key\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.prompt_template.prompt_template_config import PromptTemplateConfig\n",
    "from semantic_kernel.prompt_template.input_variable import InputVariable\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "\n",
    "# è·å–å½“å‰é»˜è®¤è®¾å®š\n",
    "req_settings = kernel.get_service(service_id).get_prompt_execution_settings_class()(service_id=service_id)\n",
    "\n",
    "trans_prompt_template_config = PromptTemplateConfig(\n",
    "    template=translate_prompt,\n",
    "    description=\"Translate Chinese to Japanese\",\n",
    "    execution_settings={service_id: req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"chinese\", description=\"The source\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "joke_prompt_template_config = PromptTemplateConfig(\n",
    "    template=joke_prompt,\n",
    "    description=\"Generate a joke about a specific topic\",\n",
    "    execution_settings={service_id: req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The topic\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "translate_function = kernel.add_function(\n",
    "    function_name=\"translate\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=trans_prompt_template_config,\n",
    ")\n",
    "\n",
    "joke_function = kernel.add_function(\n",
    "    function_name=\"joke\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=joke_prompt_template_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä¸ºäº†ç»™æ—¥æœ¬æœ‹å‹å¯„ä¿¡ï¼Œæˆ‘å­¦äº†å¾ˆå¤šæ—¥è¯­è¯æ±‡ã€‚ä½†æ˜¯å½“æˆ‘å¯„å‡ºäº†ä¿¡ä»¶åï¼Œä»–å´æ”¶åˆ°äº†ä¸€å°æ‰‹ç´™ã€‚æˆ‘æƒ³æˆ‘è¿˜éœ€è¦å†å¤šå­¦ä¹ ä¸€ä¸‹æ—¥è¯­çš„è¯­ä¹‰å·®å¼‚ã€‚\n"
     ]
    }
   ],
   "source": [
    "result = await kernel.invoke(\n",
    "    joke_function,\n",
    "    KernelArguments(\n",
    "        input=\"ä¿¡ä»¶\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "åœ¨ Prompt æ¨¡æ¿ä¸­ç›´æ¥è°ƒç”¨ Native Function ä¹Ÿå¯ä»¥ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "å·²çŸ¥ï¼Œæ•°æ®åº“å½¢å¼ä¸º\n",
    "CREATE TABLE Courses (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    course_date DATE NOT NULL,\n",
    "    start_time TIME NOT NULL,\n",
    "    end_time TIME NOT NULL,\n",
    "    course_name VARCHAR(255) NOT NULL,\n",
    "    instructor VARCHAR(255) NOT NULL\n",
    ");\n",
    "\n",
    "ç”¨è‡ªç„¶è¯­è¨€è§£é‡Šç”¨æˆ·çš„SQLæŸ¥è¯¢çš„æ„å›¾å’ŒæŸ¥è¯¢ç»“æœ\n",
    "\n",
    "ç”¨æˆ·è¾“å…¥ï¼š{{$input}}\n",
    "\n",
    "æŸ¥è¯¢ç»“æœï¼š{{DBConnectorPlugin.query_database $input}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç”¨æˆ·çš„SQLæŸ¥è¯¢æ„å›¾æ˜¯ç»Ÿè®¡æ•°æ®åº“ä¸­æ•™æˆä¸º'ç‹å“ç„¶'çš„è¯¾ç¨‹æ•°é‡ã€‚æŸ¥è¯¢ç»“æœæ˜¾ç¤ºæ•™æˆ'ç‹å“ç„¶'å…±æœ‰9é—¨è¯¾ç¨‹ã€‚\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½ native function\n",
    "kernel.add_plugin(DBConnectorPlugin(cursor), \"DBConnectorPlugin\")\n",
    "\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    description=\"æŸ¥è¯¢æ•°æ®åº“\",\n",
    "    execution_settings={service_id: req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user query\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "db_query_function = kernel.add_function(\n",
    "    function_name=\"db_query\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n",
    "\n",
    "result = await kernel.invoke(\n",
    "    db_query_function,\n",
    "    KernelArguments(\n",
    "        input=\"SELECT COUNT(*) as count FROM Courses WHERE instructor = 'ç‹å“ç„¶'\"\n",
    "    )\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ã€Memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK çš„ memory ä½¿ç”¨éå¸¸ç®€å•ï¼š\n",
    "\n",
    "1. ç”¨ `kernel.add_service()` æ·»åŠ ä¸€ä¸ªæ–‡æœ¬å‘é‡ç”ŸæˆæœåŠ¡\n",
    "2. ç”¨ `kernel.add_plugin()` æ·»åŠ ä¸€ä¸ªè¿æ¥å‘é‡æ•°æ®åº“çš„\n",
    "3. ç”¨ `memory.save_information()` ä¿å­˜ä¿¡æ¯åˆ° memory store\n",
    "4. ç”¨ `memory.search()` æœç´¢ä¿¡æ¯\n",
    "\n",
    "ä½¿ç”¨ ChatALL çš„ README.md åšæ•°æ®ï¼Œä½¿ç”¨å†…å­˜ä½œä¸º memory storeï¼Œæˆ‘ä»¬æ¼”ç¤ºä¸‹åŸºäºæ–‡æ¡£å¯¹è¯ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1ã€åˆå§‹åŒ– Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "import os\n",
    "\n",
    "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# åˆ›å»º semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# é…ç½® OpenAI æœåŠ¡ã€‚OPENAI_BASE_URL ä¼šè¢«è‡ªåŠ¨åŠ è½½ç”Ÿæ•ˆ\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "\n",
    "llm_service = OpenAIChatCompletion(\n",
    "    service_id=service_id, \n",
    "    ai_model_id=\"gpt-3.5-turbo-1106\", \n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# å°† LLM æœåŠ¡æ·»åŠ åˆ° kernel ä¸­\n",
    "kernel.add_service(llm_service)\n",
    "\n",
    "embedding_gen = OpenAITextEmbedding(\n",
    "    ai_model_id=\"text-embedding-ada-002\", \n",
    "    api_key=api_key\n",
    ")\n",
    "# å°† Embedding æœåŠ¡æ·»åŠ åˆ° kernel ä¸­\n",
    "kernel.add_service(embedding_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='TextMemoryPlugin', description=None, functions={'recall': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='recall', plugin_name='TextMemoryPlugin', description='Recall a fact from the long term memory', parameters=[KernelParameterMetadata(name='ask', description='The information to retrieve', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='collection', description='The collection to search for information.', default_value='generic', type_='str', is_required=False, type_object=<class 'str'>), KernelParameterMetadata(name='relevance', description='The relevance score, from 0.0 to 1.0; 1.0 means perfect match', default_value=0.75, type_='float', is_required=False, type_object=<class 'float'>), KernelParameterMetadata(name='limit', description='The maximum number of relevant memories to recall.', default_value=1, type_='int', is_required=False, type_object=<class 'int'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method TextMemoryPlugin.recall of TextMemoryPlugin(memory=SemanticTextMemory())>, stream_method=None), 'save': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='save', plugin_name='TextMemoryPlugin', description='Save information to semantic memory', parameters=[KernelParameterMetadata(name='text', description='The information to save.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='key', description='The unique key to associate with the information.', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='collection', description='The collection to save the information.', default_value='generic', type_='str', is_required=False, type_object=<class 'str'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='', is_required=True, type_object=None)), method=<bound method TextMemoryPlugin.save of TextMemoryPlugin(memory=SemanticTextMemory())>, stream_method=None)})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from semantic_kernel.core_plugins.text_memory_plugin import TextMemoryPlugin\n",
    "from semantic_kernel.memory.semantic_text_memory import SemanticTextMemory\n",
    "from semantic_kernel.memory.volatile_memory_store import VolatileMemoryStore\n",
    "\n",
    "# åˆ›å»ºä¸€ä¸ªï¼ˆå†…å­˜ï¼‰å‘é‡æ•°æ®åº“\n",
    "memory = SemanticTextMemory(storage=VolatileMemoryStore(), embeddings_generator=embedding_gen)\n",
    "\n",
    "# æ·»åŠ ä¸€ä¸ªè¿æ¥å‘é‡æ•°æ®åº“çš„ Plugin\n",
    "kernel.add_plugin(TextMemoryPlugin(memory), \"TextMemoryPlugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2ã€æ–‡æœ¬å‘é‡åŒ–\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.text import split_markdown_lines\n",
    "\n",
    "# è¯»å–æ–‡ä»¶å†…å®¹\n",
    "with open('ChatALL.md', 'r') as f:\n",
    "    # with open('sk_samples/SamplePlugin/SamplePlugin.py', 'r') as f:\n",
    "    content = f.read()\n",
    "\n",
    "# å°†æ–‡ä»¶å†…å®¹åˆ†ç‰‡ï¼Œå•ç‰‡æœ€å¤§ 100 tokenï¼ˆæ³¨æ„ï¼šSK çš„ text split åŠŸèƒ½ç›®å‰å¯¹ä¸­æ–‡æ”¯æŒä¸å¦‚å¯¹è‹±æ–‡æ”¯æŒå¾—å¥½ï¼‰\n",
    "lines = split_markdown_lines(content, 100)\n",
    "\n",
    "collection_id = \"generic\"\n",
    "\n",
    "# å°†åˆ†ç‰‡åçš„å†…å®¹ï¼Œå­˜å…¥å†…å­˜\n",
    "for index, line in enumerate(lines):\n",
    "    await memory.save_information(collection=collection_id, id=index, text=line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3ã€å‘é‡æœç´¢\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‹¥æœ‰å¯ä»¥è®¿é—®è¿™äº› AI çš„å¸å·ï¼Œæˆ– API tokenã€‚\n",
      "2. ä¸ AI ç½‘ç«™æœ‰å¯é çš„ç½‘ç»œè¿æ¥ã€‚\n",
      "\n",
      "## ä¸‹è½½ / å®‰è£…\n",
      "\n",
      "ä» https://github.com/sunner/ChatALL/releases ä¸‹è½½\n",
      "\n",
      "### Windows ç³»ç»Ÿ\n",
      "\n",
      "ç›´æ¥ä¸‹è½½ \\*-win.exe å®‰è£…æ–‡ä»¶å¹¶è¿è¡Œä¹‹ã€‚\n",
      "\n",
      "### macOS ç³»ç»Ÿ\n",
      "\n",
      "å¯¹äºè‹¹æœç¡…èŠ¯ç‰‡ Macï¼ˆM1ï¼ŒM2 CPUï¼‰ï¼Œè¯·ä¸‹è½½ \\*-mac-arm64.\n"
     ]
    }
   ],
   "source": [
    "result = await memory.search(collection_id, \"ChatALLæ€ä¹ˆä¸‹è½½ï¼Ÿ\")\n",
    "print(result[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4ã€ç°åœ¨ç”¨å‡½æ•°åµŒå¥—åšä¸€ä¸ªç®€å•çš„ RAG\n",
    "\n",
    "ä¾‹ï¼šåŸºäº ChatALL çš„è¯´æ˜æ–‡æ¡£ï¼Œåšé—®ç­”\n",
    "\n",
    "åœ¨è‡ªå®šä¹‰çš„ Semantic Function ä¸­ï¼ŒåµŒå¥—è°ƒç”¨å†…ç½®çš„ `TextMemorySkill`ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ä» https://github.com/sunner/ChatALL/releases ä¸‹è½½å®‰è£…æ–‡ä»¶ã€‚å¯¹äºWindowsç³»ç»Ÿï¼Œä¸‹è½½\\*-win.exeæ–‡ä»¶å¹¶è¿è¡Œï¼›å¯¹äºmacOSç³»ç»Ÿï¼Œè‹¹æœç¡…èŠ¯ç‰‡Macï¼ˆM1ï¼ŒM2 CPUï¼‰ä¸‹è½½\\*-mac-arm64æ–‡ä»¶ã€‚\n"
     ]
    }
   ],
   "source": [
    "# ç›´æ¥åœ¨ä»£ç é‡Œåˆ›å»º semantic functionã€‚çœŸå®å·¥ç¨‹ä¸å»ºè®®è¿™ä¹ˆåš\n",
    "# é‡Œé¢è°ƒç”¨äº† `recall()`\n",
    "prompt = \"\"\"\n",
    "åŸºäºä¸‹é¢çš„èƒŒæ™¯ä¿¡æ¯å›ç­”é—®é¢˜ã€‚å¦‚æœèƒŒæ™¯ä¿¡æ¯ä¸ºç©ºï¼Œæˆ–è€…å’Œé—®é¢˜ä¸ç›¸å…³ï¼Œè¯·å›ç­”\"æˆ‘ä¸çŸ¥é“\"ã€‚\n",
    "\n",
    "[èƒŒæ™¯ä¿¡æ¯å¼€å§‹]\n",
    "{{recall $input}}\n",
    "[èƒŒæ™¯ä¿¡æ¯ç»“æŸ]\n",
    "\n",
    "é—®é¢˜ï¼š{{$input}}\n",
    "å›ç­”ï¼š\n",
    "\"\"\"\n",
    "\n",
    "req_settings = kernel.get_service(service_id).get_prompt_execution_settings_class()(service_id=service_id)\n",
    "\n",
    "prompt_template_config = PromptTemplateConfig(\n",
    "    template=prompt,\n",
    "    description=\"RAGé—®ç­”\",\n",
    "    execution_settings={service_id: req_settings},\n",
    "    input_variables=[\n",
    "        InputVariable(name=\"input\", description=\"The user query\", is_required=True),\n",
    "    ],\n",
    ")\n",
    "\n",
    "rag_function = kernel.add_function(\n",
    "    function_name=\"search_and_answer\",\n",
    "    plugin_name=\"MyDemoPlugin\",\n",
    "    prompt_template_config=prompt_template_config,\n",
    ")\n",
    "\n",
    "\n",
    "result = await kernel.invoke(\n",
    "    rag_function,\n",
    "    KernelArguments(input=\"ChatALL æ€ä¹ˆä¸‹è½½\")\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5ã€è¿æ¥å…¶å®ƒ VectorDB\n",
    "\n",
    "Semantic Kernel ç›®å‰å·²ä¸å¾ˆå¤šä¸»æµçš„å‘é‡æ•°æ®åº“åšäº†é€‚é…\n",
    "\n",
    "å…·ä½“å‚è€ƒï¼šhttps://learn.microsoft.com/en-us/semantic-kernel/memories/vector-db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ã€Planner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SK çš„ Planner ç›®çš„æ˜¯ Agent å¼€å‘ã€‚åªå°è£…äº†å‡ ä¸ªåŸºæœ¬å½¢å¼ï¼ŒæŠŠæ›´å¤šçš„æ¢ç´¢ç•™ç»™äº†å¼€å‘è€…ã€‚\n",
    "\n",
    "### 6.1ã€ä»€ä¹ˆæ˜¯æ™ºèƒ½ä½“ï¼ˆAgentï¼‰\n",
    "\n",
    "å°†å¤§è¯­è¨€æ¨¡å‹ä½œä¸ºä¸€ä¸ªæ¨ç†å¼•æ“ã€‚ç»™å®šä¸€ä¸ªä»»åŠ¡ï¼Œæ™ºèƒ½ä½“è‡ªåŠ¨ç”Ÿæˆå®Œæˆä»»åŠ¡æ‰€éœ€çš„æ­¥éª¤ï¼Œæ‰§è¡Œç›¸åº”åŠ¨ä½œï¼ˆä¾‹å¦‚é€‰æ‹©å¹¶è°ƒç”¨å·¥å…·ï¼‰ï¼Œç›´åˆ°ä»»åŠ¡å®Œæˆã€‚\n",
    "\n",
    "è¿™ä¸ªå¤šæ­¥éª¤çš„è§„åˆ’è¿‡ç¨‹ï¼Œå°±ç”± **Planner** å®Œæˆã€‚\n",
    "\n",
    "<img src=\"agent-overview.png\" style=\"margin-left: 0px\" width=600px>\n",
    "\n",
    "Agent ä¸ RAG å’Œ Copilot çš„åŒºåˆ«\n",
    "\n",
    "<img src=\"types-of-agents.png\" style=\"margin-left: 0px\" width=600px/>\n",
    "\n",
    "### 6.2ã€SK Python æä¾›äº†å››ç§ Plannerï¼š\n",
    "\n",
    "1. `SequentialPlanner`\n",
    "   - åˆ¶å®šåŒ…å«ä¸€ç³»åˆ—æ­¥éª¤çš„è®¡åˆ’ï¼Œè¿™äº›æ­¥éª¤é€šè¿‡è‡ªå®šä¹‰ç”Ÿæˆçš„è¾“å…¥å’Œè¾“å‡ºå˜é‡ç›¸äº’è¿æ¥\n",
    "   - æ ¸å¿ƒ https://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/sequential_planner/Plugins/SequentialPlanning/skprompt.txt\n",
    "   - å®˜æ–¹ä¾‹ç¨‹ï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/sequential_planner.py\n",
    "2. `ActionPlanner`\n",
    "   - ç±»ä¼¼ OpenAI Function Callingï¼Œä» kernel ä¸­å·²æ³¨å†Œçš„æ‰€æœ‰ plugin ä¸­æ‰¾åˆ°ä¸€ä¸ªè¯¥æ‰§è¡Œçš„å‡½æ•°\n",
    "   - æ ¸å¿ƒ promptï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/action_planner/skprompt.txt\n",
    "   - å®˜æ–¹ä¾‹ç¨‹ï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/samples/kernel-syntax-examples/action_planner.py\n",
    "3. `StepwisePlanner`\n",
    "   - æ¯æ‰§è¡Œå®Œä¸€æ­¥ï¼Œéƒ½åšä¸€ä¸‹å¤ç›˜\n",
    "   - åªè¾“å‡º actionï¼Œä¸æ‰§è¡Œ\n",
    "   - æ ¸å¿ƒ promptï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/stepwise_planner/Plugins/StepwiseStep/skprompt.txt\n",
    "4. `BasicPlanner`\n",
    "   - **ä¸å»ºè®®ä½¿ç”¨**ã€‚æŠŠä»»åŠ¡æ‹†è§£ï¼Œè‡ªåŠ¨è°ƒç”¨å„ä¸ªå‡½æ•°ï¼Œå®Œæˆä»»åŠ¡ã€‚å®ƒåªæ˜¯ä¸ªç”¨äºåŸºç¡€éªŒè¯çš„åŠŸèƒ½ï¼Œæœ€ç»ˆä¼šè¢« `SequentialPlanner` æ›¿ä»£\n",
    "   - æ ¸å¿ƒ promptï¼šhttps://github.com/microsoft/semantic-kernel/blob/main/python/semantic_kernel/planners/basic_planner.py\n",
    "\n",
    "ä½¿ç”¨ planner çš„æ­¥éª¤éå¸¸ç®€å•ï¼š\n",
    "\n",
    "1. æŠŠ plugin æ³¨å†Œåˆ° kernel\n",
    "2. æŠŠ kernel å½“å‚æ•°å®ä¾‹åŒ–æŸä¸ª planner\n",
    "3. è°ƒç”¨ planner çš„ `create_plan_async()` æ–¹æ³•è·å¾— plan\n",
    "4. è°ƒç”¨ plan çš„ `invoke_async()` æ–¹æ³•æ‰§è¡Œ plan\n",
    "\n",
    "(æ³¨æ„ï¼Œä¸åŒ planner æ¥å£å¹¶ä¸ä¸€è‡´ï¼Œä¸èƒ½ç®€å•å¹³æ›¿)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3ã€ç”¨ Planner å®ç°ä¸€ä¸ªèƒ½ä½¿ç”¨æœç´¢å’Œæ—¥å†å·¥å…·çš„ Agent\n",
    "\n",
    "ä¾‹ï¼šå‘¨æ°ä¼¦2024å¢¨å°”æœ¬æ¼”å”±ä¼šæ˜¯æ˜ŸæœŸå‡ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.core_plugins import WebSearchEnginePlugin\n",
    "from semantic_kernel.connectors.search_engine import BingConnector\n",
    "from semantic_kernel.planners import SequentialPlanner\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion\n",
    "import os\n",
    "\n",
    "# åŠ è½½ .env åˆ°ç¯å¢ƒå˜é‡\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# åˆ›å»º semantic kernel\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "# é…ç½® OpenAI æœåŠ¡ã€‚OPENAI_BASE_URL ä¼šè¢«è‡ªåŠ¨åŠ è½½ç”Ÿæ•ˆ\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "service_id = \"default\"\n",
    "\n",
    "llm_service = OpenAIChatCompletion(\n",
    "    service_id=service_id, \n",
    "    ai_model_id=\"gpt-4\", \n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# å°† LLM æœåŠ¡æ·»åŠ åˆ° kernel ä¸­\n",
    "kernel.add_service(llm_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å…³äºå¦‚ä½•æ³¨å†Œ BING API KEY ï¼š[BING API KEY](https://agiclass.feishu.cn/wiki/JKV7wXM7IiXJFmk3ktgca1tfnfR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelPlugin(name='WebSearch', description=None, functions={'search': KernelFunctionFromMethod(metadata=KernelFunctionMetadata(name='search', plugin_name='WebSearch', description='Performs a web search for a given query', parameters=[KernelParameterMetadata(name='query', description='The search query', default_value=None, type_='str', is_required=True, type_object=<class 'str'>), KernelParameterMetadata(name='num_results', description='The number of search results to return', default_value=1, type_='int', is_required=False, type_object=<class 'int'>), KernelParameterMetadata(name='offset', description='The number of search results to skip', default_value=0, type_='int', is_required=False, type_object=<class 'int'>)], is_prompt=False, is_asynchronous=True, return_parameter=KernelParameterMetadata(name='return', description='', default_value=None, type_='str', is_required=True, type_object=None)), method=<bound method WebSearchEnginePlugin.search of <semantic_kernel.core_plugins.web_search_engine_plugin.WebSearchEnginePlugin object at 0x7fb27c137350>>, stream_method=None)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å¯¼å…¥æœç´¢ plugin\n",
    "connector = BingConnector(api_key=os.getenv(\"BING_API_KEY\"))\n",
    "kernel.add_plugin(WebSearchEnginePlugin(connector), \"WebSearch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performs a web search for a given query\n",
      "WebSearch.search: {'query': 'å‘¨æ°ä¼¦2024å¢¨å°”æœ¬æ¼”å”±ä¼šæ—¥æœŸ', 'num_results': 1, 'offset': 0}\n",
      "CONCERT_DATE=['ä½œè€…ï¼šç¥¨åšå£« 2024-03-12. å¢¨å°”æœ¬æ¼”å”±ä¼š. å¸ƒé‡Œæ–¯ç­æ¼”å”±ä¼š. æ‚‰å°¼æ¼”å”±ä¼š. 2024/2025å¹´å¾ˆå¤šæ˜æ˜Ÿå¤§è…•çš„æ¾³æ´²æ¼”å”±ä¼šè¡Œç¨‹éƒ½å·²ç»ç¡®å®šäº†ã€‚. åŒ…æ‹¬å‘¨æ°ä¼¦Jay Chouï¼Œæ—ä¿Šæ°JJ Linï¼Œé™ˆå¥•è¿…Eason Chanï¼Œäº”æœˆå¤©Maydayï¼Œæè£æµ©ï¼Œé‚“ç´«æ£‹ï¼Œç‹å˜‰å°”ï¼Œå¼ æƒ å¦¹ï¼Œæå®—ç››ï¼Œæ¢é™èŒ¹Fish Leongï¼Œæ¨åƒå¬… ...']\n",
      "Get the current day of the week\n",
      "time.dayOfWeek: {'input': '$CONCERT_DATE'}\n",
      "RESULT__DAY_OF_WEEK=Saturday\n",
      "Agent å›å¤ï¼šSaturday\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.core_plugins import MathPlugin, TextPlugin, TimePlugin\n",
    "\n",
    "kernel.add_plugin(TimePlugin(), \"time\")\n",
    "\n",
    "# åˆ›å»º planner\n",
    "planner = SequentialPlanner(kernel, service_id)\n",
    "\n",
    "# å¼€å§‹\n",
    "#query = \"å‘¨æ°ä¼¦2024å¹´4æœˆæ¼”å”±ä¼šï¼Œå“ªåœºç¦»åŒ—äº¬æœ€è¿‘ï¼Œå¸®æˆ‘è®¢ä¸€å¼ æœºç¥¨\"\n",
    "query = \"\"\"å‘¨æ°ä¼¦2024å¢¨å°”æœ¬æ¼”å”±ä¼šæ˜¯æ˜ŸæœŸå‡ \"\"\"\n",
    "\n",
    "plan = await planner.create_plan(goal=query)    \n",
    "result = await plan.invoke(kernel)\n",
    "\n",
    "for i, step in enumerate(plan._steps):\n",
    "    print(step.description)\n",
    "    print(step.plugin_name+\".\"+step.name, end=\": \")\n",
    "    print(step.parameters)\n",
    "    print(step._outputs[0] + \"=\" + str(result.metadata[\"results\"][i].value))\n",
    "\n",
    "print(f\"Agent å›å¤ï¼š{result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "è¿™é‡Œåªéœ€è¦æŒæ¡ Agent çš„å®šä¹‰å’Œå·¥ä½œåŸç†ã€‚SK è‡ªå¸¦çš„ Agent Prompt å…¶å®æ•ˆæœå¾ˆå·®ã€‚Agent çš„å®ç°æŠ€å·§æˆ‘ä»¬æœªæ¥ä¸“é—¨è®²è§£ã€‚\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**å¸¦ç€ä»¥ä¸ŠçŸ¥è¯†ï¼Œé‡æ–°å›é¡¾ä¸€ä¸‹ Kernel çš„æ„ä¹‰**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"kernel.png\" style=\"margin-left: 0px\" width=600px/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ã€VS Code æ’ä»¶\n",
    "\n",
    "è¿™æ˜¯ä¸ª VS Code çš„æ’ä»¶ï¼Œåœ¨ VS Code é‡Œå¯ä»¥ç›´æ¥åˆ›å»ºå’Œè°ƒè¯• Semantic Functionã€‚\n",
    "\n",
    "å®‰è£…åœ°å€ï¼šhttps://marketplace.visualstudio.com/items?itemName=ms-semantic-kernel.semantic-kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€è€ƒ\n",
    "\n",
    "ä»€ä¹ˆæ—¶å€™é€‚åˆç”¨ï¼š\n",
    "\n",
    "- åŸç”Ÿ API + Function Calling\n",
    "- Assistant API\n",
    "- ä¸‰æ–¹çš„ SDK, ä¾‹å¦‚ Semantic Kernel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "1. æˆ‘æ˜¯å¦åº”è¯¥ä½¿ç”¨å¼€å‘æ¡†æ¶ï¼Ÿ\n",
    "2. ä»€ä¹ˆæƒ…å†µä¸‹é€‰æ‹© SK ï¼Ÿ\n",
    "\n",
    "- å¦‚æœä½ ç»å¸¸éœ€è¦æ›¿æ¢ä¸åŒ LLM æˆ–æœ‰å¤§é‡çš„ Prompt è°ƒè¯•éœ€æ±‚ï¼Œé€‰æ‹©ä¸€ä¸ªå¼€å‘æ¡†æ¶ä¼šè®©ç”Ÿæ´»æ›´å®¹æ˜“\n",
    "- å¦‚æœä½ çš„ Prompt é‡Œæœ‰å¤§é‡åµŒå¥—è°ƒç”¨\n",
    "- å¦‚æœä½ å¿…é¡»ä½¿ç”¨ C#/JAVA æŠ€æœ¯æ ˆï¼ŒSK å¯èƒ½æ˜¯ç›®å‰å”¯ä¸€çš„é€‰æ‹©\n",
    "- å¦‚æœä½ ç”¨ Python æŠ€æœ¯æ ˆï¼Œå¯ä»¥å¯¹æ¯”ä¸€ä¸‹ LangChain å†åšå–èˆï¼ˆä¸‹èŠ‚è¯¾ç»†è®²ï¼‰\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½œä¸š\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç”¨ Semantic Kernel é‡æ„ ChatPDF çš„ä½œä¸šã€‚\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
