{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34ee8ce2-4b03-4b57-b85d-b4fb6db26570",
   "metadata": {},
   "source": [
    "# 💡 这节课会带给你\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfbc193-f8fc-4e18-85e7-45d3e8a6383a",
   "metadata": {},
   "source": [
    "1. 系统性维护、测试、监控一个 LLM 应用\n",
    "2. 学习使用主流的工具完成上述工作\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b875f9-faf2-4b87-a4b2-d2ed069a3bd0",
   "metadata": {},
   "source": [
    "## 🎓 这节课怎么学\n",
    "\n",
    "代码能力要求：**中高**，AI/数学基础要求：**低**\n",
    "\n",
    "1. 有编程基础的同学\n",
    "   - 从软件工程角度体会一个 AI 应用的开发与维护流程\n",
    "2. 没有编程基础的同学\n",
    "   - 了解一个 AI 应用开发与维护过程中涉及到的技术与问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe2fb93-5991-48e1-898b-a48ebfda9481",
   "metadata": {},
   "source": [
    "## 维护一个生产级的 LLM 应用，我们需要做什么？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb536c0-3997-457a-b360-62fbbc910454",
   "metadata": {},
   "source": [
    "1. 各种指标监控与统计：访问记录、响应时长、Token 用量、计费等等\n",
    "2. 调试 Prompt\n",
    "3. 测试/验证系统的相关评估指标\n",
    "4. 数据集管理（便于回归测试）\n",
    "5. Prompt 版本管理（便于升级/回滚）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5579d2ef-95ed-4e05-a025-940434a88100",
   "metadata": {},
   "source": [
    "## 针对以上需求，我们介绍三个生产级 LLM App 维护平台\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adb8637-fd33-438c-bfba-5acc62ff8500",
   "metadata": {},
   "source": [
    "1. 重点讲解 **LangFuse**: 开源 + SaaS（免费/付费），LangSmith 平替，可集成 LangChain 也可直接对接 OpenAI API；\n",
    "2. 简单讲解 **LangSmith**: LangChain 的官方平台，SaaS 服务（付费），非开源；\n",
    "3. 简单讲解 **Prompt Flow**：微软开发，开源 + Azure AI 云服务，可集成 Semantic Kernel（但貌合神离）。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f62d06-1ac0-499d-9985-bfcff6d67de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4068b0-b4bc-42a3-864e-47e019130832",
   "metadata": {},
   "source": [
    "## 1、LangFuse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a821ce-8be3-40d2-bb30-7ae9f0e0c7a8",
   "metadata": {},
   "source": [
    "开源，支持 LangChain 集成或原生 OpenAI API 集成\n",
    "\n",
    "官方网站：https://langfuse.com/\n",
    "\n",
    "项目地址：https://github.com/langfuse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66c22be-791e-4c1d-858f-4202a4a51786",
   "metadata": {},
   "source": [
    "1. 通过官方云服务使用：\n",
    "   - 注册: cloud.langfuse.com\n",
    "   - 创建 API Key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514461f7-d1c2-4b60-b9e2-1321fa249fe8",
   "metadata": {},
   "source": [
    "```sh\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-...\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84ccf21-e6d5-4269-9930-e936b3d081e1",
   "metadata": {},
   "source": [
    "2. 通过 Docker 本地部署\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a84beb-14f1-466c-bd29-c1dc4d1b9e40",
   "metadata": {},
   "source": [
    "```sh\n",
    "# Clone repository\n",
    "git clone https://github.com/langfuse/langfuse.git\n",
    "cd langfuse\n",
    "\n",
    "# Run server and db\n",
    "docker compose up -d\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef4acff-a558-428d-9f3d-0ef64272677c",
   "metadata": {},
   "source": [
    "```sh\n",
    "# 在自己部署的系统中生成上述两个 KEY\n",
    "# 并在环境变量中指定服务地址\n",
    "\n",
    "LANGFUSE_SECRET_KEY=\"sk-lf-...\"\n",
    "LANGFUSE_PUBLIC_KEY=\"pk-lf-..\"\n",
    "LANGFUSE_HOST=\"http://localhost:3000\"\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75383b1-fa32-4456-8c58-9ebdd6cf841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade langfuse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44563cbc-a9a0-4f8a-a00a-51e386d74007",
   "metadata": {},
   "source": [
    "### 1.1、替换 OpenAI 客户端\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46a616c4-a9e1-434d-bebe-6748fca8d5f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langfuse.openai import openai\n",
    "from langfuse import Langfuse\n",
    "import os\n",
    "\n",
    "trace = Langfuse().trace(\n",
    "    name=\"hello-world\",\n",
    "    user_id=\"wzr\",\n",
    "    release=\"v0.0.1\"\n",
    ")\n",
    "\n",
    "completion = openai.chat.completions.create(\n",
    "    name=\"hello-world\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"对我说'Hello, World!'\"}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    trace_id=trace.id,\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e6d934-c517-4481-b593-04aab3389cfd",
   "metadata": {},
   "source": [
    "### 1.1.1、几个基本概念\n",
    "\n",
    "- Trace 一般表示用户与系统的一次交互，其中记录输入、输出，也包括自定义的 metadata 比如用户名、session id 等；\n",
    "- 一个 trace 内部可以包含多个子过程，这里叫 observarions；\n",
    "- Observation 可以是多个类型：\n",
    "  - Event 是最基本的单元，用于记录一个 trace 中的每个事件；\n",
    "  - Span 表一个 trace 中的一个\"耗时\"的过程；\n",
    "  - Generation 是用于记录与 AI 模型交互的 span，例如：调用 embedding 模型、调用 LLM。\n",
    "- Observation 可以嵌套使用。\n",
    "\n",
    "<img src=\"span.png\" width=600px />ested.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0349c3-75e6-406f-aa45-7477d1557fc3",
   "metadata": {},
   "source": [
    "### 1.2、通过 LangChain 的回调集成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c47782b-9b28-4490-907a-0aa54f0b3e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langfuse.callback import CallbackHandler\n",
    "\n",
    "handler = CallbackHandler(\n",
    "    trace_name=\"SayHello\",\n",
    "    user_id=\"wzr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee41e249-1151-440b-bba0-334cd024b9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    HumanMessagePromptTemplate.from_template(\"Say hello to {input}!\")\n",
    "])\n",
    "\n",
    "\n",
    "# 定义输出解析器\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a71703-76d6-450f-9a1c-e0bca46ddde6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/langchain_core/_api/beta_decorator.py:86: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  warn_beta(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello AGIClass!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input=\"AGIClass\", config={\"callbacks\": [handler]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b67f7a-6c4b-4c90-86fa-2f052e732087",
   "metadata": {},
   "source": [
    "### 1.3、构建一个实际应用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b251ff93-100e-4277-a2ca-e45c3917e999",
   "metadata": {},
   "source": [
    "**AGI 课堂跟课助手**，根据课程内容，判断学生问题是否需要老师解答\n",
    "\n",
    "1. 判断该问题是否需要老师解答，回复'Y'或'N'\n",
    "2. 判断该问题是否已有同学问过\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e216f6d0-88cb-4bdb-bc1d-3bd932b7d4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建 PromptTemplate\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "你是AIGC课程的助教，你的工作是从学员的课堂交流中选择出需要老师回答的问题，加以整理以交给老师回答。\n",
    " \n",
    "课程内容:\n",
    "{outlines}\n",
    "*********\n",
    "学员输入:\n",
    "{user_input}\n",
    "*********\n",
    "如果这是一个需要老师答疑的问题，回复Y，否则回复N。\n",
    "只回复Y或N，不要回复其他内容。\"\"\")\n",
    "\n",
    "check_duplicated = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "已有提问列表:\n",
    "[\n",
    "{question_list}\n",
    "]\n",
    "*********\n",
    "新提问:\n",
    "{user_input}\n",
    "*********\n",
    "已有提问列表是否有和新提问类似的问题? 回复Y或N, Y表示有，N表示没有。\n",
    "只回复Y或N，不要回复其他内容。\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4ac9d67-725c-43bc-a08b-cb2e187bd060",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlines = \"\"\"\n",
    "LangChain\n",
    "模型 I/O 封装\n",
    "模型的封装\n",
    "模型的输入输出\n",
    "PromptTemplate\n",
    "OutputParser\n",
    "数据连接封装\n",
    "文档加载器：Document Loaders\n",
    "文档处理器\n",
    "内置RAG：RetrievalQA\n",
    "记忆封装：Memory\n",
    "链架构：Chain/LCEL\n",
    "大模型时代的软件架构：Agent\n",
    "ReAct\n",
    "SelfAskWithSearch\n",
    "LangServe\n",
    "LangChain.js\n",
    "\"\"\"\n",
    "\n",
    "question_list = [\n",
    "    \"LangChain可以商用吗\",\n",
    "    \"LangChain开源吗\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15cc8923-701f-4fe9-91e8-68a2cf723880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建 chain\n",
    "model = ChatOpenAI(temperature=0, model_kwargs={\"seed\": 42})\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain1 = (\n",
    "    need_answer\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain2 = (\n",
    "    check_duplicated\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a781e6-cd35-4cb3-b9ac-f933bd1c93e2",
   "metadata": {},
   "source": [
    "### 1.3.1、用 Trace 记录一个多次调用 LLM 的过程\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7753345a-5536-45e2-be95-2c923cb50824",
   "metadata": {},
   "source": [
    "TRACE (id: trace_id)\n",
    "|\n",
    "|-- SPAN: LLMCain (id: generated by Langfuse)\n",
    "|   |\n",
    "|   |-- GENERATION: OpenAI (id: generated by Langfuse)\n",
    "|\n",
    "|-- SPAN: LLMCain (id: generated by 'next_span_id')\n",
    "|   |\n",
    "|   |-- GENERATION: OpenAI (id: generated by Langfuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0de918b2-9e99-479d-8035-f838972ee152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langfuse.client import Langfuse\n",
    "\n",
    "# 创建一个新trace\n",
    "\n",
    "\n",
    "def create_trace(user_id):\n",
    "    langfuse = Langfuse()\n",
    "    # 创建一个不重复的 id\n",
    "    trace_id = str(uuid.uuid4())\n",
    "    trace = langfuse.trace(\n",
    "        name=\"agiclass_assistant\",\n",
    "        id=trace_id,\n",
    "        user_id=user_id\n",
    "    )\n",
    "    return trace\n",
    "\n",
    "# 主流程\n",
    "\n",
    "\n",
    "def verify_question(\n",
    "    question: str,\n",
    "    outlines: str,\n",
    "    question_list: list,\n",
    "    user_id: str,\n",
    ") -> bool:\n",
    "    trace = create_trace(user_id)\n",
    "    handler = trace.get_langchain_handler()\n",
    "    # 判断是否需要回答\n",
    "    if chain1.invoke(\n",
    "        {\"user_input\": question, \"outlines\": outlines},\n",
    "        config={\"callbacks\": [handler]}\n",
    "    ) == 'Y':\n",
    "        # 判断是否为重复问题\n",
    "        if chain2.invoke(\n",
    "            {\"user_input\": question,\n",
    "                \"question_list\": \"\\n\".join(question_list)},\n",
    "            config={\"callbacks\": [handler]}\n",
    "        ) == 'N':\n",
    "            question_list.append(question)\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ff6685-2a26-467b-9a2a-0497833d9162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# 实际调用\n",
    "ret = verify_question(\n",
    "    # \"LangChain和SK哪个好用\",\n",
    "    # \"LangChain支持Java吗\",\n",
    "    \"老师好\",\n",
    "    outlines,\n",
    "    question_list,\n",
    "    user_id=\"wzr\",\n",
    ")\n",
    "print(ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bb2e27-4c18-424c-99dd-b3c02c29dfcb",
   "metadata": {},
   "source": [
    "### 1.3.2、用 Session 记录一个用户的多轮对话\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a12e26a6-67b6-4182-ae9b-772551f02cc4",
   "metadata": {},
   "source": [
    "SESSION (id: session_id)\n",
    "|\n",
    "|-- TRACE\n",
    "|-- TRACE\n",
    "|-- TRACE\n",
    "|-- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0c37548-2b93-404e-b4c3-e65d7e9ac019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  你是谁\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 我是AGIClass的课程助理。我可以帮助您解答关于课程内容和学习任务的问题。有什么我可以帮到您的吗？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  你好\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: 你好！有什么问题我可以帮您解答呢？\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  \n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,  # 等价于OpenAI接口中的assistant role\n",
    "    HumanMessage,  # 等价于OpenAI接口中的user role\n",
    "    SystemMessage  # 等价于OpenAI接口中的system role\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"你是AGIClass的课程助理。\"),\n",
    "]\n",
    "\n",
    "handler = CallbackHandler(\n",
    "    user_id=\"wzr\",\n",
    "    session_id=\"my_chat_session2\"\n",
    ")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.strip() == \"\":\n",
    "        break\n",
    "    messages.append(HumanMessage(content=user_input))\n",
    "    response = llm.invoke(messages, config={\"callbacks\": [handler]})\n",
    "    print(\"AI: \"+response.content)\n",
    "    messages.append(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c529d3b7-91f2-41fa-a090-04f4746e72d0",
   "metadata": {},
   "source": [
    "### 1.4、数据集与测试\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4507fd3-616e-45be-9d0f-49ae347019b7",
   "metadata": {},
   "source": [
    "### 1.4.1、在线标注\n",
    "\n",
    "<img src=\"annotation.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fe4c35-fba3-49d9-ae9e-9d2bdffb7b0b",
   "metadata": {},
   "source": [
    "### 1.4.2、上传已有数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef67abc0-09d9-4548-92e8-158ed23f77c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 调整数据格式 {\"input\":{...},\"expected_output\":\"label\"}\n",
    "data = []\n",
    "with open('my_annotations.jsonl', 'r', encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        item = {\n",
    "            \"input\": {\n",
    "                \"outlines\": example[\"outlines\"],\n",
    "                \"user_input\": example[\"user_input\"]\n",
    "            },\n",
    "            \"expected_output\": example[\"label\"]\n",
    "        }\n",
    "        data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "156368ef-50aa-449f-922b-5a7ffd73f86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:13<00:00,  3.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from langfuse import Langfuse\n",
    "from langfuse.model import CreateDatasetRequest, CreateDatasetItemRequest\n",
    "from tqdm import tqdm\n",
    "\n",
    "# init\n",
    "langfuse = Langfuse()\n",
    "\n",
    "# 创建数据集，如果已存在不会重复创建\n",
    "# langfuse.create_dataset(name=\"assistant-data\")\n",
    "\n",
    "# 考虑演示运行速度，只上传前50条数据\n",
    "for item in tqdm(data[:50]):\n",
    "    langfuse.create_dataset_item(\n",
    "        dataset_name=\"my-dataset\",\n",
    "        input=item[\"input\"],\n",
    "        expected_output=item[\"expected_output\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260b9e3b-0684-4273-b2af-2919c077b059",
   "metadata": {},
   "source": [
    "### 1.4.3、定义评估函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6155790-14c6-4931-b8c1-1c8de93538f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_evaluation(output, expected_output):\n",
    "    return output == expected_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35ef8d5-cc46-4350-8c9a-03ab54c08a26",
   "metadata": {},
   "source": [
    "### 1.4.4、运行测试\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ee1c5a-f3ac-4024-89ab-3d54b877b845",
   "metadata": {},
   "source": [
    "Prompt 模板与 Chain（LCEL）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd0c5623-af29-4c3a-b010-75f5b3e4ae67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "你是AIGC课程的助教，你的工作是从学员的课堂交流中选择出需要老师回答的问题，加以整理以交给老师回答。\n",
    " \n",
    "课程内容:\n",
    "{outlines}\n",
    "*********\n",
    "学员输入:\n",
    "{user_input}\n",
    "*********\n",
    "如果这是一个需要老师答疑的问题，回复Y，否则回复N。\n",
    "只回复Y或N，不要回复其他内容。\"\"\")\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_kwargs={\"seed\": 42})\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain_v1 = (\n",
    "    need_answer\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3264acb-295c-4aa4-9ea4-9aca340bf52a",
   "metadata": {},
   "source": [
    "在数据集上测试效果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fad90f27-5aab-423a-96e8-1dc73a903cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from langfuse import Langfuse\n",
    "\n",
    "langfuse = Langfuse()\n",
    "\n",
    "\n",
    "def run_evaluation(chain, dataset_name, run_name):\n",
    "    dataset = langfuse.get_dataset(dataset_name)\n",
    "\n",
    "    def process_item(item):\n",
    "        handler = item.get_langchain_handler(run_name=run_name)\n",
    "\n",
    "        # Assuming chain.invoke is a synchronous function\n",
    "        output = chain.invoke(item.input, config={\"callbacks\": [handler]})\n",
    "\n",
    "        # Assuming handler.root_span.score is a synchronous function\n",
    "        handler.root_span.score(\n",
    "            name=\"accuracy\",\n",
    "            value=simple_evaluation(output, item.expected_output)\n",
    "        )\n",
    "        print('.', end='', flush=True)\n",
    "\n",
    "    for item in dataset.items:\n",
    "        process_item(item)\n",
    "\n",
    "    # 建议并行处理\n",
    "    # with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        # executor.map(process_item, dataset.items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c641ff7c-87d3-4c65-8ee6-e7c27aa35dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "run_evaluation(chain_v1, \"my-dataset\", \"v1-\"+str(uuid.uuid4())[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e617b8-d637-4b7e-977c-0802359c19e4",
   "metadata": {},
   "source": [
    "### 1.4.5、Prompt 调优与回归测试\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08909eaa-566f-49c6-bde1-ddbbbb223438",
   "metadata": {},
   "source": [
    "优化 Prompt：试试思维链（回忆[第二课](../02-prompt/index.ipynb)）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "910b8550-8dde-44f4-8983-5ea398449f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "你是AIGC课程的助教，你的工作是从学员的课堂交流中选择出需要老师回答的问题，加以整理以交给老师回答。\n",
    "\n",
    "你的选择需要遵循以下原则：\n",
    "1 需要老师回答的问题是指与课程内容或AI/LLM相关的技术问题；\n",
    "2 评论性的观点、闲聊、表达模糊不清的句子，不需要老师回答；\n",
    "3 学生输入不构成疑问句的，不需要老师回答；\n",
    "4 学生问题中如果用“这”、“那”等代词指代，不算表达模糊不清，请根据问题内容判断是否需要老师回答。\n",
    " \n",
    "课程内容:\n",
    "{outlines}\n",
    "*********\n",
    "学员输入:\n",
    "{user_input}\n",
    "*********\n",
    "Analyse the student's input according to the lecture's contents and your criteria.\n",
    "Output your analysis process step by step.\n",
    "Finally, output a single letter Y or N in a separate line.\n",
    "Y means that the input needs to be answered by the teacher.\n",
    "N means that the input does not needs to be answered by the teacher.\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70d0f431-c8a3-4385-9738-ecf24a0b6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "import re\n",
    "\n",
    "\n",
    "class MyOutputParser(BaseOutputParser):\n",
    "    \"\"\"自定义parser，从思维链中取出最后的Y/N\"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        matches = re.findall(r'[YN]', text)\n",
    "        return matches[-1] if matches else 'N'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59b2375a-2b7d-4398-8a63-0c4c289da34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_v2 = (\n",
    "    need_answer\n",
    "    | model\n",
    "    | MyOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788ae178-c194-42c5-b21f-0d165b5506f0",
   "metadata": {},
   "source": [
    "回归测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76456796-2fa2-4cd9-ae71-d6fbcb65d472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..................................................."
     ]
    }
   ],
   "source": [
    "run_evaluation(chain_v2, \"my-dataset\", \"cot-\"+str(uuid.uuid4())[:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf5d874-95bb-4a81-8924-f97f00a6a6dc",
   "metadata": {},
   "source": [
    "### 1.5、Prompt 版本管理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11a845-f9e2-4110-9223-53ffc428b280",
   "metadata": {},
   "source": [
    "<img src=\"prompt_management.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278643de-1354-4526-9f25-553d62deee23",
   "metadata": {},
   "source": [
    "目前只支持 Langfuse 自己的 SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fece2096-b931-45cb-9754-28b3969b8cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "你是AIGC课程的助教，你的工作是从学员的课堂交流中选择出需要老师回答的问题，加以整理以交给老师回答。\n",
      " \n",
      "课程内容:\n",
      "test\n",
      "*********\n",
      "学员输入:\n",
      "老师好\n",
      "*********\n",
      "如果这是一个需要老师答疑的问题，回复Y，否则回复N。\n",
      "只回复Y或N，不要回复其他内容。\n"
     ]
    }
   ],
   "source": [
    "# 按名称加载\n",
    "prompt = langfuse.get_prompt(\"need_answer_v1\")\n",
    "\n",
    "# 按名称和版本号加载\n",
    "prompt = langfuse.get_prompt(\"need_answer_v1\", version=2)\n",
    "\n",
    "# 对模板中的变量赋值\n",
    "compiled_prompt = prompt.compile(input=\"老师好\", outlines=\"test\")\n",
    "\n",
    "print(compiled_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c19bb1b6-e346-4967-bfb8-22993e00a187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'temperature': 0}\n"
     ]
    }
   ],
   "source": [
    "# 获取 config\n",
    "\n",
    "prompt = langfuse.get_prompt(\"need_answer_v1\", version=5)\n",
    "\n",
    "print(prompt.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc85360b-ab9a-4fac-919b-c84b691e760c",
   "metadata": {},
   "source": [
    "### 1.6、如何比较两个句子的相似性：一些经典 NLP 的评测方法（选）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2ea3a5-e750-4a21-a092-a7d1cadf1a21",
   "metadata": {},
   "source": [
    "1. **编辑距离**：也叫莱文斯坦距离(Levenshtein),是针对二个字符串的差异程度的量化量测，量测方式是看至少需要多少次的处理才能将一个字符串变成另一个字符串。\n",
    "   - 具体计算过程是一个动态规划算法：https://zhuanlan.zhihu.com/p/164599274\n",
    "   - 衡量两个句子的相似度时，可以以词为单位计算\n",
    "2. **BLEU Score**:\n",
    "   - 计算输出与参照句之间的 n-gram 准确率（n=1...4）\n",
    "   - 对短输出做惩罚\n",
    "   - 在整个测试集上平均下述值\n",
    "   - 完整计算公式：$\\mathrm{BLEU}_4=\\min\\left(1,\\frac{output-length}{reference-length}\\right)\\left(\\prod_{i=1}^4 precision_i\\right)^{\\frac{1}{4}}$\n",
    "   - 函数库：https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
    "3. **Rouge Score**:\n",
    "   - Rouge-N：将模型生成的结果和标准结果按 N-gram 拆分后，只计算召回率；\n",
    "   - Rouge-L: 利用了最长公共子序列（Longest Common Sequence），计算：$P=\\frac{LCS(c,r)}{len(c)}$, $R=\\frac{LCS(c,r)}{len(r)}$, $F=\\frac{(1+\\beta^2)PR}{R+\\beta^2P}$\n",
    "   - 函数库：https://pypi.org/project/rouge-score/\n",
    "   - 对比 BLEU 与 ROUGE：\n",
    "     - BLEU 能评估流畅度，但指标偏向于较短的翻译结果（brevity penalty 没有想象中那么强）\n",
    "     - ROUGE 不管流畅度，所以只适合深度学习的生成模型：结果都是流畅的前提下，ROUGE 反应参照句中多少内容被生成的句子包含（召回）\n",
    "4. **METEOR**: 另一个从机器翻译领域借鉴的指标。与 BLEU 相比，METEOR 考虑了更多的因素，如同义词匹配、词干匹配、词序等，因此它通常被认为是一个更全面的评价指标。\n",
    "   - 对语言学和语义词表有依赖，所以对语言依赖强。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f653506c-68d6-44ac-ad08-861ec4b54650",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>此类方法常用于对文本生成模型的自动化评估。实际使用中，我们通常更关注相对变化而不是绝对值（调优过程中指标是不是在变好）。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677669d-a7cb-469d-860c-02338c8fe225",
   "metadata": {},
   "source": [
    "### 1.7、基于 LLM 的测试方法\n",
    "\n",
    "LangFuse 集成了一些原生的基于 LLM 的自动测试标准。\n",
    "\n",
    "具体参考：https://langfuse.com/docs/scores/model-based-evals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c522be03-c20b-48ad-b5fb-c1436ce9ae74",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>此类方法，对于用于评估的 LLM 自身能力有要求。需根据具体情况选择使用。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48f2552-f3af-4484-91e3-3c2308c05921",
   "metadata": {},
   "source": [
    "## 2、LangSmith\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b102754-5cbc-457f-82c7-7264795bd2ea",
   "metadata": {},
   "source": [
    "LangChain 官方的 SaaS 服务，不开源，注册需要排队。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f950af-34cd-43f1-a1a2-ed18d3743f1f",
   "metadata": {},
   "source": [
    "平台入口：https://www.langchain.com/langsmith\n",
    "\n",
    "文档地址：https://python.langchain.com/docs/langsmith/walkthrough\n",
    "\n",
    "将你的 LangChain 应用与 LangSmith 链接，需要：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc59a7c-53c9-438b-a439-752eb68e817b",
   "metadata": {},
   "source": [
    "1. 安装 LangSmith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a797c266-3cac-468b-8ce8-3892d32df9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade langchain\n",
    "%pip install --upgrade langsmith"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0abc6ce9-e39a-4c3f-8182-95c7c333729c",
   "metadata": {},
   "source": [
    "2. 注册账号，并申请一个`LANGCHAIN_API_KEY`\n",
    "3. 在环境变量中设置以下值\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77875bb-76ca-4737-afa9-5796064e6e10",
   "metadata": {},
   "source": [
    "```shell\n",
    "export LANGCHAIN_TRACING_V2=true\n",
    "export LANGCHAIN_PROJECT=YOUR_PROJECT_NAME #自定义项目名称（可选）\n",
    "export LANGCHAIN_API_KEY=LANGCHAIN_API_KEY # LangChain API Key\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de823435-67b7-4f96-974a-4588fad8a1ef",
   "metadata": {},
   "source": [
    "3. 程序中的调用将自动被记录\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df088b92-f10c-4d79-9b3c-43281d26edeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__44058e8374214bef8cf7eb0842718fe9\"\n",
    "# 可选\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"hello-world-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dddaf145-15f2-450e-903c-2de85d6aeb44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello AGIClass! How can I assist you today?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 定义语言模型\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# 定义Prompt模板\n",
    "prompt = PromptTemplate.from_template(\"Say hello to {input}!\")\n",
    "\n",
    "# 定义输出解析器\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = (\n",
    "    {\"input\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "chain.invoke(\"AGIClass\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59edfa6-2282-48ee-9c97-7af6a2532ddf",
   "metadata": {},
   "source": [
    "<img src=\"langsmith-example.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a31a3eb-9fbf-408c-b2fc-5b5f3cb16268",
   "metadata": {},
   "source": [
    "### 2.1、基本功能演示\n",
    "\n",
    "1. Traces\n",
    "2. LLM Calls\n",
    "3. Monitor\n",
    "4. Playground\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c59c7c0-9e49-4230-841c-900487b716cb",
   "metadata": {},
   "source": [
    "### 2.2、数据集管理与测试\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e0dd2-7ea4-4799-9fc6-4b786a8302d3",
   "metadata": {},
   "source": [
    "### 2.2.1、在线标注演示\n",
    "\n",
    "<img src=\"langsmith-annotation.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60b4a82-8f91-480e-8e7c-0f7941314c7c",
   "metadata": {},
   "source": [
    "### 2.2.2、上传数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2f6863f5-e368-4ec7-a51c-97ea6c6032b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "with open('my_annotations.jsonl', 'r', encoding='utf-8') as fp:\n",
    "    for line in fp:\n",
    "        example = json.loads(line.strip())\n",
    "        item = {\n",
    "            \"input\": {\n",
    "                \"outlines\": example[\"outlines\"],\n",
    "                \"user_input\": example[\"user_input\"]\n",
    "            },\n",
    "            \"expected_output\": example[\"label\"]\n",
    "        }\n",
    "        data.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e978a2d-74cd-4b9c-a3cb-18f81b091c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "dataset_name = \"assistant-0319\"\n",
    "\n",
    "dataset = client.create_dataset(\n",
    "    dataset_name,  # 数据集名称\n",
    "    description=\"AGIClass线上跟课助手的标注数据\",  # 数据集描述\n",
    ")\n",
    "\n",
    "\n",
    "client.create_examples(\n",
    "    inputs=[{\"input\": item[\"input\"]} for item in data[:50]],\n",
    "    outputs=[{\"output\": item[\"expected_output\"]} for item in data[:50]],\n",
    "    dataset_id=dataset.id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f473e5-3873-42d0-b900-f0d9cea94412",
   "metadata": {},
   "source": [
    "### 2.2.3、评估函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "195f62cc-43ae-4120-9008-a2ac456cfd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import StringEvaluator\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import re\n",
    "from typing import Optional, Any\n",
    "\n",
    "\n",
    "class AccuracyEvaluator(StringEvaluator):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @property\n",
    "    def requires_input(self) -> bool:\n",
    "        return False\n",
    "\n",
    "    @property\n",
    "    def requires_reference(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    @property\n",
    "    def evaluation_name(self) -> str:\n",
    "        return \"accuracy\"\n",
    "\n",
    "    def _evaluate_strings(\n",
    "        self,\n",
    "        prediction: str,\n",
    "        input: Optional[str] = None,\n",
    "        reference: Optional[str] = None,\n",
    "        **kwargs: Any\n",
    "    ) -> dict:\n",
    "        return {\"score\": int(prediction == reference)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3813b43c-7ecd-46e3-9a2c-9b880bfea413",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import EvaluatorType\n",
    "from langchain.smith import RunEvalConfig\n",
    "\n",
    "evaluation_config = RunEvalConfig(\n",
    "    # 自定义评估标准\n",
    "    custom_evaluators=[AccuracyEvaluator()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcef2db5-39d8-4e0a-aa1c-4235944acd93",
   "metadata": {},
   "source": [
    "### 2.2.4、运行测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c56d52ec-d58a-4720-a9a4-1b8f8130d7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "need_answer = PromptTemplate.from_template(\"\"\"\n",
    "*********\n",
    "你是AIGC课程的助教，你的工作是从学员的课堂交流中选择出需要老师回答的问题，加以整理以交给老师回答。\n",
    " \n",
    "课程内容:\n",
    "{outlines}\n",
    "*********\n",
    "学员输入:\n",
    "{user_input}\n",
    "*********\n",
    "如果这是一个需要老师答疑的问题，回复Y，否则回复N。\n",
    "只回复Y或N，不要回复其他内容。\"\"\")\n",
    "\n",
    "model = ChatOpenAI(temperature=0, model_kwargs={\"seed\": 42})\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain_v1 = (\n",
    "    {\n",
    "        \"outlines\": lambda x: x[\"input\"][\"outlines\"],\n",
    "        \"user_input\": lambda x: x[\"input\"][\"user_input\"],\n",
    "    }\n",
    "    | need_answer\n",
    "    | model\n",
    "    | parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b92f2e89-0bc6-41df-b5b4-7fa938639795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for project 'spotless-snail-84' at:\n",
      "https://smith.langchain.com/o/97b8262a-9ab9-4b43-afeb-21ea05a90ba7/datasets/a03163ad-d4e4-452b-88f5-26192921e12b/compare?selectedSessions=a8b5c11b-e83e-4bf3-a6f9-f7c786cf6996\n",
      "\n",
      "View all tests for Dataset assistant-0319 at:\n",
      "https://smith.langchain.com/o/97b8262a-9ab9-4b43-afeb-21ea05a90ba7/datasets/a03163ad-d4e4-452b-88f5-26192921e12b\n",
      "[------------------------------------------------->] 50/50"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Experiment Results:</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feedback.accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>b2fd467c-57f7-487c-bdea-4c6686260971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.660000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.463369</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.478518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.169098</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.231957</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.340298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441578</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.517325</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.128715</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        feedback.accuracy error  execution_time  \\\n",
       "count           50.000000     0       50.000000   \n",
       "unique                NaN     0             NaN   \n",
       "top                   NaN   NaN             NaN   \n",
       "freq                  NaN   NaN             NaN   \n",
       "mean             0.660000   NaN        0.463369   \n",
       "std              0.478518   NaN        0.169098   \n",
       "min              0.000000   NaN        0.231957   \n",
       "25%              0.000000   NaN        0.340298   \n",
       "50%              1.000000   NaN        0.441578   \n",
       "75%              1.000000   NaN        0.517325   \n",
       "max              1.000000   NaN        1.128715   \n",
       "\n",
       "                                      run_id  \n",
       "count                                     50  \n",
       "unique                                    50  \n",
       "top     b2fd467c-57f7-487c-bdea-4c6686260971  \n",
       "freq                                       1  \n",
       "mean                                     NaN  \n",
       "std                                      NaN  \n",
       "min                                      NaN  \n",
       "25%                                      NaN  \n",
       "50%                                      NaN  \n",
       "75%                                      NaN  \n",
       "max                                      NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.smith import (\n",
    "    arun_on_dataset,\n",
    "    run_on_dataset,\n",
    ")\n",
    "\n",
    "results = await arun_on_dataset(\n",
    "    dataset_name=dataset_name,\n",
    "    llm_or_chain_factory=chain_v1,\n",
    "    evaluation=evaluation_config,\n",
    "    verbose=True,\n",
    "    client=client,\n",
    "    project_metadata={\n",
    "        \"version\": \"prompt_v1\",\n",
    "    },  # 可选，自定义的标识\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1d803-5b09-4756-89a1-8377c22300e5",
   "metadata": {},
   "source": [
    "### 2.2.5、基于 LLM 的评估函数\n",
    "\n",
    "https://docs.smith.langchain.com/evaluation/faq/evaluator-implementations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b8f664-41a2-41f2-8b00-73bd0abf27ef",
   "metadata": {},
   "source": [
    "## 3、Prompt Flow\n",
    "\n",
    "<img src=\"prompt-flow.png\" width=\"600px\">\n",
    "\n",
    "项目地址 https://github.com/microsoft/promptflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f43012-06b6-42d7-a7c5-766f90bf8840",
   "metadata": {},
   "source": [
    "### 3.1、安装\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb12a0-3f01-49bf-aaac-d86a93beb665",
   "metadata": {},
   "source": [
    "```sh\n",
    "pip install promptflow promptflow-tools\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8ae3f-b928-4f78-9e25-47033a2b63fd",
   "metadata": {},
   "source": [
    "### 3.2、命令行运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7edaba2-12f6-4414-8d32-b98493a8793e",
   "metadata": {},
   "source": [
    "```sh\n",
    "pf flow init --flow ./my_chatbot --type chat\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa22b652-e67d-41bb-bc7c-0bdb94e475e4",
   "metadata": {},
   "source": [
    "### 3.3、VSCode 插件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248c5ce9-292c-43b0-ab04-81ba5d0eae68",
   "metadata": {},
   "source": [
    "https://marketplace.visualstudio.com/items?itemName=prompt-flow.prompt-flow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c85434c-d9b1-4e68-9050-690db2589a9a",
   "metadata": {},
   "source": [
    "<img src=\"vsc.png\" width=\"600px\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e1f7b8-e7da-4c80-887c-44d4ad89478f",
   "metadata": {},
   "source": [
    "### 3.4、与 Semantic Kernel 结合使用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151cf220-934e-4e11-8fc0-bea8604a38b0",
   "metadata": {},
   "source": [
    "<演示>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58790105-fafd-4a07-afab-7ff72fb0c4af",
   "metadata": {},
   "source": [
    "Azure 云服务：https://learn.microsoft.com/en-us/azure/machine-learning/prompt-flow/get-started-prompt-flow?view=azureml-api-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e365c65-9d5a-4fba-8d9d-b1be247f90c2",
   "metadata": {},
   "source": [
    "## 总结\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881722dc-400a-451a-abbf-4324a0a5c2db",
   "metadata": {},
   "source": [
    "管理一个 LLM 应用的全生命周期，需要用到以下工具：\n",
    "\n",
    "1. 调试 Prompt 的 Playground\n",
    "2. 测试/验证系统的相关指标\n",
    "3. 数据集管理\n",
    "4. 各种指标监控与统计：访问量、响应时长、Token 费等等\n",
    "\n",
    "根据自己的技术栈，选择：\n",
    "\n",
    "1. LangFuse：开源平台，支持 LangChain 和原生 OpenAI API\n",
    "2. LangSmith: LangChain 的原始管理平台\n",
    "3. Prompt Flow：开源平台，支持 Semantic Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd761c5-485c-4f1c-993c-990e13a1aca6",
   "metadata": {},
   "source": [
    "## 作业\n",
    "\n",
    "选择一个工具平台，对自己之前开发的系统或模型做批量测试\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
