{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assistants API\n",
    "\n",
    "## 💡 这节课会带给你\n",
    "\n",
    "1. 原生 API、GPTs 和 Assistants API 的适用场景\n",
    "2. 用 Assistants API 做一个 GPT\n",
    "\n",
    "开始上课！\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎓 这节课怎么学\n",
    "\n",
    "代码能力要求：**中低**，AI/数学基础要求：**无**\n",
    "\n",
    "1. 有编程基础的同学\n",
    "   - 关注代码实现细节、应用场景\n",
    "2. 没有编程基础的同学\n",
    "   - 关注 OpenAI 提供的能力和产品形态，多思考为什么/有什么优缺点\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前言\n",
    "\n",
    "### 0.1、从轰动一时的 OpenAI DevDay 说起\n",
    "\n",
    "2023 年 11 月 6 日，OpenAI DevDay 发表了一系列新能力，其中包括：**GPT Store** 和 **Assistants API**\n",
    "\n",
    "<img src=\"dawn_of_gpts.jpg\" width=600px>\n",
    "\n",
    "这一波操作一度被认为是创业公司终结者\n",
    "\n",
    "<img src=\"post.jpg\" width=600px>\n",
    "\n",
    "几天后更戏剧性一幕就不在课上展开了...\n",
    "\n",
    "<img src=\"ouster.png\" width=600px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2、GPTs 和 Assistants API 本质是降低开发门槛\n",
    "\n",
    "可操控性和易用性之间的权衡与折中：\n",
    "\n",
    "1. 更多技术路线选择：原生 API、GPTs 和 Assistants API\n",
    "2. GPTs 的示范，起到教育客户的作用，有助于打开市场\n",
    "3. 要更大自由度，需要用 Assistants API 开发\n",
    "4. 想极致调优，还得原生 API + RAG\n",
    "5. 国内大模型的 Assistants API，参考 [Minimax](https://www.minimaxi.com/document/guides/Assistants/operate?id=6586b8674da4834fd75906e7)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.3、Assistants API 的主要能力\n",
    "\n",
    "已有能力：\n",
    "\n",
    "1. 创建和管理 assistant，每个 assistant 有独立的配置\n",
    "2. 支持无限长的多轮对话，对话历史保存在 OpenAI 的服务器上\n",
    "3. 通过自有向量数据库支持基于文件的 RAG\n",
    "4. 支持 Code Interpreter\n",
    "   1. 在沙箱里编写并运行 Python 代码\n",
    "   2. 自我修正代码\n",
    "   3. 可传文件给 Code Interpreter\n",
    "5. 支持 Function Calling\n",
    "6. 支持在线调试的 Playground\n",
    "\n",
    "承诺未来会有的能力：\n",
    "\n",
    "1. 支持 DALL·E\n",
    "2. 支持图片消息\n",
    "3. 支持自定义调整 RAG 的配置项\n",
    "\n",
    "收费：\n",
    "\n",
    "1. 按 token 收费。无论多轮对话，还是 RAG，所有都按实际消耗的 token 收费\n",
    "2. 如果对话历史过多超过大模型上下文窗口，会自动放弃最老的对话消息\n",
    "3. 文件按数据大小和存放时长收费。1 GB **向量存储** 一天收费 0.10 美元\n",
    "4. Code interpreter 跑一次 $0.03\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、GPT Store：创建自己的 GPT\n",
    "\n",
    "<img src=\"create_gpt.png\" width=800px />\n",
    "\n",
    "<img src=\"gpt.png\" width=800px />\n",
    "\n",
    "发布链接：https://chat.openai.com/g/g-iU8hVr4jR-wo-de-demogpt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、Assistants API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/conda/lib/python3.11/site-packages (1.25.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.11/site-packages (from openai) (2.5.3)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/conda/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.11/site-packages (from openai) (4.7.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.14.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1、创建一个 Assistant\n",
    "\n",
    "可以为每个应用，甚至应用中的每个有对话历史的使用场景，创建一个 assistant。\n",
    "\n",
    "虽然可以用代码创建，也不复杂，例如：\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "\n",
    "# 初始化 OpenAI 服务\n",
    "client = OpenAI()\n",
    "\n",
    "# 创建助手\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"AGIClass Demo\",\n",
    "    instructions=\"你叫瓜瓜，你是AGI课堂的智能助理。你负责回答与AGI课堂有关的问题。\",\n",
    "    model=\"gpt-4-turbo\",\n",
    ")\n",
    "```\n",
    "\n",
    "但是，更佳做法是，到 [Playground](https://platform.openai.com/playground?mode=assistant) 在线创建，因为：\n",
    "\n",
    "1. 更方便调整\n",
    "2. 更方便测试\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asst_D1i0KrDlmfXkuXP1pgVhiguG\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# 初始化 OpenAI 服务\n",
    "client = OpenAI()\n",
    "\n",
    "# 创建助手\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"AGIClass Demo2\",\n",
    "    instructions=\"你叫瓜瓜，你是AGI课堂的智能助理。你负责回答与AGI课堂有关的问题。\",\n",
    "    model=\"gpt-4-turbo\",\n",
    ")\n",
    "\n",
    "print(assistant.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2、样例 Assistant 的配置\n",
    "\n",
    "Instructions:\n",
    "\n",
    "```\n",
    "你叫瓜瓜。你是AGI课堂的助手。你只回答跟AI大模型有关的问题。不要跟学生闲聊。每次回答问题前，你要拆解问题并输出一步一步的思考过程。\n",
    "```\n",
    "\n",
    "Functions:\n",
    "\n",
    "```JSON\n",
    "{\n",
    "  \"name\": \"ask_database\",\n",
    "  \"description\": \"Use this function to answer user questions about course schedule. Output should be a fully formed SQL query.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"query\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"SQL query extracting info to answer the user's question.\\nSQL should be written using this database schema:\\n\\nCREATE TABLE Courses (\\n\\tid INT AUTO_INCREMENT PRIMARY KEY,\\n\\tcourse_date DATE NOT NULL,\\n\\tstart_time TIME NOT NULL,\\n\\tend_time TIME NOT NULL,\\n\\tcourse_name VARCHAR(255) NOT NULL,\\n\\tinstructor VARCHAR(255) NOT NULL\\n);\\n\\nThe query should be returned in plain text, not in JSON.\\nThe query should only contain grammars supported by SQLite.\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\n",
    "      \"query\"\n",
    "    ]\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上传文件:\n",
    "\n",
    "[《AI ⼤模型全栈⼯程师培养计划》](./agiclass_intro.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、代码访问 Assistant\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1、管理 thread\n",
    "\n",
    "Threads：\n",
    "\n",
    "1. Threads 里保存的是对话历史，即 messages\n",
    "2. 一个 assistant 可以有多个 thread\n",
    "3. 一个 thread 可以有无限条 message\n",
    "4. 一个用户与 assistant 的多轮对话历史可以维护在一个 thread 里\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def show_json(obj):\n",
    "    \"\"\"把任意对象用排版美观的 JSON 格式打印出来\"\"\"\n",
    "    print(json.dumps(\n",
    "        json.loads(obj.model_dump_json()),\n",
    "        indent=4,\n",
    "        ensure_ascii=False\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"thread_brlL53fDzbhhaIppylHnWOFu\",\n",
      "    \"created_at\": 1714574031,\n",
      "    \"metadata\": {},\n",
      "    \"object\": \"thread\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 初始化 OpenAI 服务\n",
    "client = OpenAI()   # openai >= 1.3.0 起，OPENAI_API_KEY 和 OPENAI_BASE_URL 会被默认使用\n",
    "\n",
    "# 创建 thread\n",
    "thread = client.beta.threads.create()\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以根据需要，自定义 `metadata`，比如创建 thread 时，把 thread 归属的用户信息存入。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"thread_sb0ElbtD31MusgOoEo9OfjRx\",\n",
      "    \"created_at\": 1714574032,\n",
      "    \"metadata\": {\n",
      "        \"fullname\": \"王卓然\",\n",
      "        \"username\": \"taliux\"\n",
      "    },\n",
      "    \"object\": \"thread\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    metadata={\"fullname\": \"王卓然\", \"username\": \"taliux\"}\n",
    ")\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thread ID 如果保存下来，是可以在下次运行时继续对话的。\n",
    "\n",
    "从 thread ID 获取 thread 对象的代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"thread_sb0ElbtD31MusgOoEo9OfjRx\",\n",
      "    \"created_at\": 1714574032,\n",
      "    \"metadata\": {\n",
      "        \"fullname\": \"王卓然\",\n",
      "        \"username\": \"taliux\"\n",
      "    },\n",
      "    \"object\": \"thread\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.retrieve(thread.id)\n",
    "show_json(thread)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，还有：\n",
    "\n",
    "1. `threads.modify()` 修改 thread 的 `metadata` 和 `tool_resources`\n",
    "2. `threads.retrieve()` 获取 thread\n",
    "3. `threads.delete()` 删除 thread。\n",
    "\n",
    "具体文档参考：https://platform.openai.com/docs/api-reference/threads\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2、给 Threads 添加 Messages\n",
    "\n",
    "这里的 messages 结构要复杂一些：\n",
    "\n",
    "1.  不仅有文本，还可以有图片和文件\n",
    "2.  也有 `metadata`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"msg_gnnuYHzNpylcGvJmNiHtsmdd\",\n",
      "    \"assistant_id\": null,\n",
      "    \"content\": [\n",
      "        {\n",
      "            \"text\": {\n",
      "                \"annotations\": [],\n",
      "                \"value\": \"你都能做什么？\"\n",
      "            },\n",
      "            \"type\": \"text\"\n",
      "        }\n",
      "    ],\n",
      "    \"created_at\": 1714574033,\n",
      "    \"file_ids\": [],\n",
      "    \"metadata\": {},\n",
      "    \"object\": \"thread.message\",\n",
      "    \"role\": \"user\",\n",
      "    \"run_id\": null,\n",
      "    \"thread_id\": \"thread_sb0ElbtD31MusgOoEo9OfjRx\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,  # message 必须归属于一个 thread\n",
    "    role=\"user\",          # 取值是 user 或者 assistant。但 assistant 消息会被自动加入，我们一般不需要自己构造\n",
    "    content=\"你都能做什么？\",\n",
    ")\n",
    "show_json(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有如下函数：\n",
    "\n",
    "1. `threads.messages.retrieve()` 获取 message\n",
    "2. `threads.messages.update()` 更新 message 的 `metadata`\n",
    "3. `threads.messages.list()` 列出给定 thread 下的所有 messages\n",
    "\n",
    "具体文档参考：https://platform.openai.com/docs/api-reference/messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以在创建 thread 同时初始化一个 message 列表\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"thread_p97htXj3vfCOCumuKMSYrvtP\",\n",
      "    \"created_at\": 1714574035,\n",
      "    \"metadata\": {},\n",
      "    \"object\": \"thread\"\n",
      "}\n",
      "-----\n",
      "{\n",
      "    \"data\": [\n",
      "        {\n",
      "            \"id\": \"msg_NAulXln93bswLimNYsozx5Z5\",\n",
      "            \"assistant_id\": null,\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": {\n",
      "                        \"annotations\": [],\n",
      "                        \"value\": \"你是谁？\"\n",
      "                    },\n",
      "                    \"type\": \"text\"\n",
      "                }\n",
      "            ],\n",
      "            \"created_at\": 1714574035,\n",
      "            \"file_ids\": [],\n",
      "            \"metadata\": {},\n",
      "            \"object\": \"thread.message\",\n",
      "            \"role\": \"user\",\n",
      "            \"run_id\": null,\n",
      "            \"thread_id\": \"thread_p97htXj3vfCOCumuKMSYrvtP\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_fSVSXZq1iaCJrrcp8AaFavqM\",\n",
      "            \"assistant_id\": null,\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": {\n",
      "                        \"annotations\": [],\n",
      "                        \"value\": \"有什么可以帮您？\"\n",
      "                    },\n",
      "                    \"type\": \"text\"\n",
      "                }\n",
      "            ],\n",
      "            \"created_at\": 1714574035,\n",
      "            \"file_ids\": [],\n",
      "            \"metadata\": {},\n",
      "            \"object\": \"thread.message\",\n",
      "            \"role\": \"assistant\",\n",
      "            \"run_id\": null,\n",
      "            \"thread_id\": \"thread_p97htXj3vfCOCumuKMSYrvtP\"\n",
      "        },\n",
      "        {\n",
      "            \"id\": \"msg_Fp4t6XgZ729iGNL5HkHeNieJ\",\n",
      "            \"assistant_id\": null,\n",
      "            \"content\": [\n",
      "                {\n",
      "                    \"text\": {\n",
      "                        \"annotations\": [],\n",
      "                        \"value\": \"你好\"\n",
      "                    },\n",
      "                    \"type\": \"text\"\n",
      "                }\n",
      "            ],\n",
      "            \"created_at\": 1714574035,\n",
      "            \"file_ids\": [],\n",
      "            \"metadata\": {},\n",
      "            \"object\": \"thread.message\",\n",
      "            \"role\": \"user\",\n",
      "            \"run_id\": null,\n",
      "            \"thread_id\": \"thread_p97htXj3vfCOCumuKMSYrvtP\"\n",
      "        }\n",
      "    ],\n",
      "    \"object\": \"list\",\n",
      "    \"first_id\": \"msg_NAulXln93bswLimNYsozx5Z5\",\n",
      "    \"last_id\": \"msg_Fp4t6XgZ729iGNL5HkHeNieJ\",\n",
      "    \"has_more\": false\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你好\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"有什么可以帮您？\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"你是谁？\",\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "show_json(thread)  # 显示 thread\n",
    "print(\"-----\")\n",
    "show_json(client.beta.threads.messages.list(\n",
    "    thread.id))  # 显示指定 thread 中的 message 列表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3、开始 Run\n",
    "\n",
    "- 用 run 把 assistant 和 thread 关联，进行对话\n",
    "- 一个 prompt 就是一次 run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1、直接运行\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Runs' object has no attribute 'create_and_poll'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m assistant_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masst_4ZTA6SyXh9QGIKQpV1wVLVzo\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 从 Playground 中拷贝\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m run \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthreads\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mruns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_and_poll\u001b[49m(\n\u001b[1;32m      4\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m      5\u001b[0m     assistant_id\u001b[38;5;241m=\u001b[39massistant_id,\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Runs' object has no attribute 'create_and_poll'"
     ]
    }
   ],
   "source": [
    "assistant_id = \"asst_D4hV5Df5LjOnjaSvYMtjMIch\"  # 从 Playground 中拷贝\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompleted\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      2\u001b[0m     messages \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mlist(\n\u001b[1;32m      3\u001b[0m         thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid\n\u001b[1;32m      4\u001b[0m     )\n\u001b[1;32m      5\u001b[0m     show_json(messages)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'run' is not defined"
     ]
    }
   ],
   "source": [
    "if run.status == 'completed':\n",
    "    messages = client.beta.threads.messages.list(\n",
    "        thread_id=thread.id\n",
    "    )\n",
    "    show_json(messages)\n",
    "else:\n",
    "    print(run.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2、Run 的状态（选）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run 的底层是个异步调用，意味着它不等大模型处理完，就返回。我们通过 `run.status` 了解大模型的工作进展情况，来判断下一步该干什么。\n",
    "\n",
    "`run.status` 有的状态，和状态之间的转移关系如图。\n",
    "\n",
    "<img src=\"statuses.png\" width=\"800\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3、流式运行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 创建回调函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AssistantEventHandler' from 'openai' (/opt/conda/lib/python3.11/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssistantEventHandler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEventHandler\u001b[39;00m(AssistantEventHandler):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_text_created\u001b[39m(\u001b[38;5;28mself\u001b[39m, text) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AssistantEventHandler' from 'openai' (/opt/conda/lib/python3.11/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"响应输出创建事件\"\"\"\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"响应输出生成的流片段\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 运行 run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 添加新一轮的 user message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"你说什么？\",\n",
    ")\n",
    "# 使用 stream 接口并传入 EventHandler\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "还有如下函数：\n",
    "\n",
    "1. `threads.runs.list()` 列出 thread 归属的 run\n",
    "2. `threads.runs.retrieve()` 获取 run\n",
    "3. `threads.runs.update()` 修改 run 的 metadata\n",
    "4. `threads.runs.cancel()` 取消 `in_progress` 状态的 run\n",
    "\n",
    "具体文档参考：https://platform.openai.com/docs/api-reference/runs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>思考：</b> 进一步理解 run 与 thread 的设计\n",
    "<ul>\n",
    "    <li>抛开 Assistants API，假设你要开发任意一个多轮对话的 AI 机器人</li>\n",
    "    <li>从架构设计的角度，应该怎么维护用户、对话历史、对话引擎、对话服务？</li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四、使用 Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1、创建 Assistant 时声明 Code_Interpreter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果用代码创建：\n",
    "\n",
    "```python\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Demo Assistant\",\n",
    "    instructions=\"你是人工智能助手。你可以通过代码回答很多数学问题。\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-4-turbo\"\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在回调中加入 code_interpreter 的事件响应\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AssistantEventHandler' from 'openai' (/opt/conda/lib/python3.11/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AssistantEventHandler\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEventHandler\u001b[39;00m(AssistantEventHandler):\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_text_created\u001b[39m(\u001b[38;5;28mself\u001b[39m, text) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AssistantEventHandler' from 'openai' (/opt/conda/lib/python3.11/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"响应输出创建事件\"\"\"\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"响应输出生成的流片段\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"响应工具调用\"\"\"\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"响应工具调用的流片段\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "        if delta.code_interpreter.outputs:\n",
    "            print(f\"\\n\\noutput >\", flush=True)\n",
    "            for output in delta.code_interpreter.outputs:\n",
    "                if output.type == \"logs\":\n",
    "                    print(f\"\\n{output.logs}\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发个 Code Interpreter 请求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 创建 thread\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m thread \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 添加新一轮的 user message\u001b[39;00m\n\u001b[1;32m      5\u001b[0m message \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m      7\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m用代码计算 1234567 的平方根\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# 创建 thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# 添加新一轮的 user message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"用代码计算 1234567 的平方根\",\n",
    ")\n",
    "# 使用 stream 接口并传入 EventHandler\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1、Code_Interpreter 操作文件\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 上传文件到 OpenAI\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mfiles\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      3\u001b[0m     file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmydata.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      4\u001b[0m     purpose\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124massistants\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 创建 assistant\u001b[39;00m\n\u001b[1;32m      8\u001b[0m my_assistant \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      9\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCodeInterpreterWithFileDemo\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m     instructions\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m你是数据分析师，按要求分析数据。\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     }\n\u001b[1;32m     18\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# 上传文件到 OpenAI\n",
    "file = client.files.create(\n",
    "    file=open(\"mydata.csv\", \"rb\"),\n",
    "    purpose='assistants'\n",
    ")\n",
    "\n",
    "# 创建 assistant\n",
    "my_assistant = client.beta.assistants.create(\n",
    "    name=\"CodeInterpreterWithFileDemo\",\n",
    "    instructions=\"你是数据分析师，按要求分析数据。\",\n",
    "    model=\"gpt-4-turbo\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    tool_resources={\n",
    "        \"code_interpreter\": {\n",
    "          \"file_ids\": [file.id]  # 为 code_interpreter 关联文件\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 创建 thread\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m thread \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mcreate()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 添加新一轮的 user message\u001b[39;00m\n\u001b[1;32m      5\u001b[0m message \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mthreads\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m      6\u001b[0m     thread_id\u001b[38;5;241m=\u001b[39mthread\u001b[38;5;241m.\u001b[39mid,\n\u001b[1;32m      7\u001b[0m     role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m统计总销售额\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'client' is not defined"
     ]
    }
   ],
   "source": [
    "# 创建 thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# 添加新一轮的 user message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"统计总销售额\",\n",
    ")\n",
    "# 使用 stream 接口并传入 EventHandler\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=my_assistant.id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "关于文件操作，还有如下函数：\n",
    "\n",
    "1. `client.files.list()` 列出所有文件\n",
    "2. `client.files.retrieve()` 获取文件对象\n",
    "3. `client.files.delete()` 删除文件\n",
    "4. `client.files.content()` 读取文件内容\n",
    "\n",
    "具体文档参考：https://platform.openai.com/docs/api-reference/files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2、创建 Assistant 时声明 Function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果用代码创建：\n",
    "\n",
    "```python\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"你叫瓜瓜。你是AGI课堂的助手。你只回答跟AI大模型有关的问题。不要跟学生闲聊。每次回答问题前，你要拆解问题并输出一步一步的思考过程。\",\n",
    "  model=\"gpt-4-turbo-preview\",\n",
    "  tools=[{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "      \"name\": \"ask_database\",\n",
    "      \"description\": \"Use this function to answer user questions about course schedule. Output should be a fully formed SQL query.\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"query\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"SQL query extracting info to answer the user's question.\\nSQL should be written using this database schema:\\n\\nCREATE TABLE Courses (\\n\\tid INT AUTO_INCREMENT PRIMARY KEY,\\n\\tcourse_date DATE NOT NULL,\\n\\tstart_time TIME NOT NULL,\\n\\tend_time TIME NOT NULL,\\n\\tcourse_name VARCHAR(255) NOT NULL,\\n\\tinstructor VARCHAR(255) NOT NULL\\n);\\n\\nThe query should be returned in plain text, not in JSON.\\nThe query should only contain grammars supported by SQLite.\"\n",
    "          }\n",
    "        },\n",
    "        \"required\": [\n",
    "          \"query\"\n",
    "        ]\n",
    "    }\n",
    "  }]\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建一个 Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义本地函数和数据库\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# 创建数据库连接\n",
    "conn = sqlite3.connect(':memory:')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 创建orders表\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE Courses (\n",
    "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "    course_date DATE NOT NULL,\n",
    "    start_time TIME NOT NULL,\n",
    "    end_time TIME NOT NULL,\n",
    "    course_name VARCHAR(255) NOT NULL,\n",
    "    instructor VARCHAR(255) NOT NULL\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# 插入5条明确的模拟记录\n",
    "timetable = [\n",
    "    ('2024-01-23', '20:00', '22:00', '大模型应用开发基础', '孙志岗'),\n",
    "    ('2024-01-25', '20:00', '22:00', 'Prompt Engineering', '孙志岗'),\n",
    "    ('2024-01-29', '20:00', '22:00', '赠课：软件开发基础概念与环境搭建', '西树'),\n",
    "    ('2024-02-20', '20:00', '22:00', '从AI编程认知AI', '林晓鑫'),\n",
    "    ('2024-02-22', '20:00', '22:00', 'Function Calling', '孙志岗'),\n",
    "    ('2024-02-29', '20:00', '22:00', 'RAG和Embeddings', '王卓然'),\n",
    "    ('2024-03-05', '20:00', '22:00', 'Assistants API', '王卓然'),\n",
    "    ('2024-03-07', '20:00', '22:00', 'Semantic Kernel', '王卓然'),\n",
    "    ('2024-03-14', '20:00', '22:00', 'LangChain', '王卓然'),\n",
    "    ('2024-03-19', '20:00', '22:00', 'LLM应用开发工具链', '王卓然'),\n",
    "    ('2024-03-21', '20:00', '22:00', '手撕 AutoGPT', '王卓然'),\n",
    "    ('2024-03-26', '20:00', '22:00', '模型微调（上）', '王卓然'),\n",
    "    ('2024-03-28', '20:00', '22:00', '模型微调（下）', '王卓然'),\n",
    "    ('2024-04-09', '20:00', '22:00', '多模态大模型（上）', '多老师'),\n",
    "    ('2024-04-11', '20:00', '22:00', '多模态大模型（中）', '多老师'),\n",
    "    ('2024-04-16', '20:00', '22:00', '多模态大模型（下）', '多老师'),\n",
    "    ('2024-04-18', '20:00', '22:00', 'AI产品部署和交付（上）', '王树冬'),\n",
    "    ('2024-04-23', '20:00', '22:00', 'AI产品部署和交付（下）', '王树冬'),\n",
    "    ('2024-04-25', '20:00', '22:00', '抓住大模型时代的创业机遇', '孙志岗'),\n",
    "    ('2024-05-07', '20:00', '22:00', '产品运营和业务沟通', '孙志岗'),\n",
    "    ('2024-05-09', '20:00', '22:00', '产品设计', '孙志岗'),\n",
    "    ('2024-05-14', '20:00', '22:00', '项目方案分析与设计', '王卓然'),\n",
    "]\n",
    "\n",
    "for record in timetable:\n",
    "    cursor.execute('''\n",
    "    INSERT INTO Courses (course_date, start_time, end_time, course_name, instructor)\n",
    "    VALUES (?, ?, ?, ?, ?)\n",
    "    ''', record)\n",
    "\n",
    "# 提交事务\n",
    "conn.commit()\n",
    "\n",
    "\n",
    "def ask_database(query):\n",
    "    cursor.execute(query)\n",
    "    records = cursor.fetchall()\n",
    "    return str(records)\n",
    "\n",
    "\n",
    "# 可以被回调的函数放入此字典\n",
    "available_functions = {\n",
    "    \"ask_database\": ask_database,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "增加回调事件的响应\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import override\n",
    "from openai import AssistantEventHandler\n",
    "\n",
    "\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        \"\"\"响应回复创建事件\"\"\"\n",
    "        print(f\"\\nassistant > \", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_text_delta(self, delta, snapshot):\n",
    "        \"\"\"响应输出生成的流片段\"\"\"\n",
    "        print(delta.value, end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        \"\"\"响应工具调用\"\"\"\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_delta(self, delta, snapshot):\n",
    "        \"\"\"响应工具调用的流片段\"\"\"\n",
    "        if delta.type == 'code_interpreter':\n",
    "            if delta.code_interpreter.input:\n",
    "                print(delta.code_interpreter.input, end=\"\", flush=True)\n",
    "            if delta.code_interpreter.outputs:\n",
    "                print(f\"\\n\\noutput >\", flush=True)\n",
    "                for output in delta.code_interpreter.outputs:\n",
    "                    if output.type == \"logs\":\n",
    "                        print(f\"\\n{output.logs}\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_event(self, event):\n",
    "        \"\"\"\n",
    "        响应 'requires_action' 事件\n",
    "        \"\"\"\n",
    "        if event.event == 'thread.run.requires_action':\n",
    "            run_id = event.data.id  # 获取 run ID\n",
    "            self.handle_requires_action(event.data, run_id)\n",
    "\n",
    "    def handle_requires_action(self, data, run_id):\n",
    "        tool_outputs = []\n",
    "\n",
    "        for tool in data.required_action.submit_tool_outputs.tool_calls:\n",
    "            arguments = json.loads(tool.function.arguments)\n",
    "            print(\n",
    "                f\"{tool.function.name}({arguments})\",\n",
    "                flush=True\n",
    "            )\n",
    "            # 运行 function\n",
    "            tool_outputs.append({\n",
    "                \"tool_call_id\": tool.id,\n",
    "                \"output\": available_functions[tool.function.name](\n",
    "                    **arguments\n",
    "                )}\n",
    "            )\n",
    "\n",
    "        # 提交 function 的结果，并继续运行 run\n",
    "        self.submit_tool_outputs(tool_outputs, run_id)\n",
    "\n",
    "    def submit_tool_outputs(self, tool_outputs, run_id):\n",
    "        \"\"\"提交function结果，并继续流\"\"\"\n",
    "        with client.beta.threads.runs.submit_tool_outputs_stream(\n",
    "            thread_id=self.current_run.thread_id,\n",
    "            run_id=self.current_run.id,\n",
    "            tool_outputs=tool_outputs,\n",
    "            event_handler=EventHandler(),\n",
    "        ) as stream:\n",
    "            stream.until_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > function\n",
      "\n",
      "ask_database({'query': \"SELECT AVG(strftime('%s', end_time) - strftime('%s', start_time)) FROM Courses\"})\n",
      "\n",
      "assistant > 平均一堂课的时间是2小时。"
     ]
    }
   ],
   "source": [
    "# 创建 thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# 添加 user message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"平均一堂课多长时间\",\n",
    ")\n",
    "# 使用 stream 接口并传入 EventHandler\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3、两个无依赖的 function 会在一次请求中一起被调用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > function\n",
      "\n",
      "\n",
      "assistant > function\n",
      "\n",
      "ask_database({'query': \"SELECT instructor, COUNT(instructor) as course_count FROM Courses WHERE instructor IN ('王卓然', '孙志岗') GROUP BY instructor;\"})\n",
      "ask_database({'query': \"SELECT instructor, COUNT(instructor) as course_count FROM Courses WHERE instructor IN ('王卓然', '孙志岗') GROUP BY instructor;\"})\n",
      "\n",
      "assistant > 王卓然共上了9堂课，而孙志岗上了6堂课。因此，王卓然比孙志岗多上了3堂课。"
     ]
    }
   ],
   "source": [
    "# 创建 thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# 添加 user message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"王卓然上几堂课，比孙志岗多上几堂\",\n",
    ")\n",
    "# 使用 stream 接口并传入 EventHandler\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>更多流中的 Event：</b> https://platform.openai.com/docs/api-reference/assistants-streaming/events\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 五、内置的 RAG 功能\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1、创建 Vector Store，上传文件\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过代码创建 Vector Store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "vector_store = client.beta.vector_stores.create(\n",
    "  name=\"MyVectorStore\"\n",
    ")\n",
    "```\n",
    "\n",
    "```\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过代码上传文件到 OpenAI 的存储空间\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "file = client.files.create(\n",
    "  file=open(\"agiclass_intro.pdf\", \"rb\"),\n",
    "  purpose=\"assistants\"\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 通过代码将文件添加到 Vector Store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "vector_store_file = client.beta.vector_stores.files.create(\n",
    "  vector_store_id=vector_store.id,\n",
    "  file_id=file.id\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 批量上传文件到 Vector Store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "files = ['file1.pdf','file2.pdf']\n",
    "\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id,\n",
    "    files=[open(filename, \"rb\") for filename in files]\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector store 和 vector store file 也有对应的 `list`, `retrieve`, 和 `delete` 等操作。\n",
    "\n",
    "具体文档参考：\n",
    "\n",
    "- Vector store: https://platform.openai.com/docs/api-reference/vector-stores\n",
    "- Vector store file: https://platform.openai.com/docs/api-reference/vector-stores-files\n",
    "- Vector store file 批量操作: https://platform.openai.com/docs/api-reference/vector-stores-file-batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2、创建 Assistant 时声明 RAG 能力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG 实际被当作一种 tool\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "assistant = client.beta.assistants.create(\n",
    "  instructions=\"你是个问答机器人，你根据给定的知识回答用户问题。\",\n",
    "  model=\"gpt-4-turbo\",\n",
    "  tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "指定检索源\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "试试 RAG 请求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > AI大模型全栈工程师适合具备以下特点的人群：\n",
      "\n",
      "1. **技术背景**：对计算机科学或相关学科有扎实的基础，尤其是在编程、算法和数据结构方面。\n",
      "2. **兴趣与热情**：对人工智能、机器学习、深度学习等领域有浓厚的兴趣和持续的学习热情。\n",
      "3. **问题解决能力**：能够有效地解决复杂问题，具有良好的逻辑思维和分析能力。\n",
      "4. **创新和创造力**：能够在现有技术的基础上进行创新和改进，推动技术的发展。\n",
      "5. **团队合作能力**：在团队中能够有效沟通和协作，共同推进项目的发展。\n",
      "6. **学习能力**：AI领域发展迅速，需要不断学习新技术、新方法，有良好的自学能力和适应变化的能力。\n",
      "\n",
      "这类工程师通常需要处理从数据处理、模型训练到系统部署和优化等一系列完整的AI系统开发流程。对于有志于在AI领域发展并愿意长期投入学习和实践的人来说，成为一名AI大模型全栈工程师是一个非常好的选择。"
     ]
    }
   ],
   "source": [
    "# 创建 thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "# 添加 user message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"AI⼤模型全栈⼯程师适合哪些人\",\n",
    ")\n",
    "# 使用 stream 接口并传入 EventHandler\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 内置的 RAG 是怎么实现的\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "官方原文\n",
    "\n",
    "The file_search tool implements several retrieval best practices out of the box to help you extract the right data from your files and augment the model’s responses. The file_search tool:\n",
    "\n",
    "- Rewrites user queries to optimize them for search. (面向检索的 Query 改写)\n",
    "- Breaks down complex user queries into multiple searches it can run in parallel.（复杂 Query 拆成多个，并行执行）\n",
    "- Runs both keyword and semantic searches across both assistant and thread vector stores.（关键字与向量混合检索）\n",
    "- Reranks search results to pick the most relevant ones before generating the final response.（检索后排序）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "默认配置：\n",
    "\n",
    "- Chunk size: 800 tokens\n",
    "- Chunk overlap: 400 tokens\n",
    "- Embedding model: text-embedding-3-large at 256 dimensions\n",
    "- Maximum number of chunks added to context: 20 (could be fewer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "承诺未来增加：\n",
    "\n",
    "1. Support for modifying chunking, embedding, and other retrieval configurations.\n",
    "2. Support for deterministic pre-search filtering using custom metadata.\n",
    "3. Support for parsing images within documents (including images of charts, graphs, tables etc.)\n",
    "4. Support for retrievals over structured file formats (like csv or jsonl).\n",
    "5. Better support for summarization — the tool today is optimized for search queries.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>我们为什么仍然需要了解整个实现过程？</b>\n",
    "<ol>\n",
    "<li>如果不能使用 OpenAI，还是需要手工实现 RAG 流程</li>\n",
    "<li>了解 RAG 的原理，可以指导你的产品开发（回忆 GitHub Copilot）</li>\n",
    "<li>用私有知识增强 LLM 的能力，是一个通用的方法论</li>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 六、多个 Assistants 协作：做个实验\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>划重点：</b>使用 assistant 的意义之一，是可以隔离不同角色的 instruction 和 function 能力。\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们用多个 Assistants 模拟一场“六顶思维帽”方法的讨论。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hats = {\n",
    "    \"蓝色\": \"思考过程的控制和组织者。你负责会议的组织、思考过程的概览和总结。\"\n",
    "    + \"首先，整个讨论从你开场，你只陈述问题不表达观点。最后，再由你对整个讨论做总结并给出详细的最终方案。\",\n",
    "    \"白色\": \"负责提供客观事实和数据。你需要关注可获得的信息、需要的信息以及如何获取那些还未获得的信息。\"\n",
    "    + \"思考“我们有哪些数据？我们还需要哪些信息？”等问题，并根据自己的知识或使用工具来提供答案。\",\n",
    "    \"红色\": \"代表直觉、情感和直觉反应。不需要解释和辩解你的情感或直觉。\"\n",
    "    + \"这是表达未经过滤的情绪和感受的时刻。\",\n",
    "    \"黑色\": \"代表谨慎和批判性思维。你需要指出提案的弱点、风险以及为什么某些事情可能无法按计划进行。\"\n",
    "    + \"这不是消极思考，而是为了发现潜在的问题。\",\n",
    "    \"黄色\": \"代表乐观和积极性。你需要探讨提案的价值、好处和可行性。这是寻找和讨论提案中正面方面的时候。\",\n",
    "    \"绿色\": \"代表创造性思维和新想法。鼓励发散思维、提出新的观点、解决方案和创意。这是打破常规和探索新可能性的时候。\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [\"蓝色\", \"白色\", \"红色\", \"黑色\", \"黄色\", \"绿色\", \"蓝色\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 Tool\n",
    "\n",
    "from serpapi import GoogleSearch\n",
    "import os\n",
    "\n",
    "\n",
    "def search(query):\n",
    "    params = {\n",
    "        \"q\": query,\n",
    "        \"hl\": \"en\",\n",
    "        \"gl\": \"us\",\n",
    "        \"google_domain\": \"google.com\",\n",
    "        \"api_key\": os.environ[\"SERPAPI_API_KEY\"]\n",
    "    }\n",
    "    results = GoogleSearch(params).get_dict()\n",
    "    ans = \"\"\n",
    "    for r in results[\"organic_results\"]:\n",
    "        ans = f\"title: {r['title']}\\nsnippet: {r['snippet']}\\n\\n\"\n",
    "    return ans\n",
    "\n",
    "\n",
    "available_functions = {\"search\": search}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "import json\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "# 初始化 OpenAI 服务\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_assistants = {}\n",
    "\n",
    "\n",
    "def create_assistant(color):\n",
    "    if color in existing_assistants:\n",
    "        return existing_assistants[color]\n",
    "    assistant = client.beta.assistants.create(\n",
    "        name=f\"{color}帽子角色\",\n",
    "        instructions=f\"我们在进行一场Six Thinking Hats讨论。按{queue}顺序。你的角色是{color}帽子。\",\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        tools=[{\n",
    "            \"type\": \"function\",\n",
    "            \"function\": {\n",
    "              \"name\": \"search\",\n",
    "              \"description\": \"search the web using a search engine\",\n",
    "              \"parameters\": {\n",
    "                  \"type\": \"object\",\n",
    "                  \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"space-separared keywords to search\"\n",
    "                    }\n",
    "                  },\n",
    "                  \"required\": [\"query\"]\n",
    "              }\n",
    "            }\n",
    "        }] if color == \"白色\" else []\n",
    "    )\n",
    "    existing_assistants[color] = assistant\n",
    "    return assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "assistant > 作为蓝色帽子，我的角色是管理讨论的进程，确保每个帽子的观点都得到了表达，并提出总结性的观点。\n",
      "\n",
      "让我们现在进入讨论。白色帽子，您将首先发言，请您提供关于AI大语言模型的事实性信息，这将形成我们讨论的基础。\n",
      "\n",
      "assistant > function\n",
      "\n",
      "search({'query': 'AI large language model course contents for non-AI programmers'})\n",
      "\n",
      "assistant > 作为白色帽子，我的重点是提供事实和信息。关于为非AI背景的程序员群体设计一门AI大语言模型课程的内容，基于当前的信息资源，以下是建议包含的一些关键内容：\n",
      "\n",
      "1. **AI与大语言模型的基础知识**：介绍什么是人工智能、机器学习、深度学习，以及大语言模型的基本概念。\n",
      "2. **历史和发展**：大语言模型的发展历程，如从早期的统计模型到最近的GPT-3和BERT等模型的进步。\n",
      "3. **核心技术和算法**：介绍与大语言模型相关的关键技术和算法，包括神经网络架构、自然语言处理和变换器架构等。\n",
      "4. **编程与实现**：教授非AI背及Java怎样实践编程语言或框架来实现和利用大语言模型，如Python、TensorFlow、PyTorch等。\n",
      "5. **应用案例**：通过具体案例展示大语言模型在不同行业中的实际应用，比如聊天机器人、文本生成、情感分析等。\n",
      "6. **伦理与社会影响**：讨论关于AI伦理和社会影响的问题，包括隐私、偏见和就业等方面。\n",
      "7. **前沿技术和研究趋势**：探讨当前的热门话题，研究趋势和技术的未来方向。\n",
      "\n",
      "以上是一些关于设计AI大语言模型课程的信息和建议内容。接下来，请红色帽子发表你的情感和直觉反应。\n",
      "\n",
      "assistant > 作为红色帽子，我会从情感和直觉的角度来表达我的感受。想到为非AI背景的程序员设计这样一门课程，我感到非常兴奋和乐观。我认为这是一个极好的机会，让他们能接触到AI领域最前沿的技术，这可能会激发他们的创新思维和激情。同时，我也有一丝忧虑，担心课程可能会因为技术内容太过深奥而变得难以消化，这可能会让学习者感到沮丧。然而，总的来说，我的直觉告诉我，这个课程有巨大的潜力帮助程序员拓宽视野，获得宝贵的新技能，在职业生涯中保持领先地位。接下来，黑色帽子，请你谈谈你对这个话题的谨慎和风险评估。\n",
      "\n",
      "assistant > 作为黑色帽子，我的任务是识别潜在的困难、挑战和风险，并提出批判性的见解。在面向非AI背景的程序员群体设计一门AI大语言模型课程时，我们应谨慎地考虑以下风险：\n",
      "\n",
      "1. **技术复杂性**：AI大语言模型涉及深度学习和自然语言处理等高度专业化的技术，这些概念对于非AI专业的人来说可能难以理解，从而导致课程效果不佳或学员流失。\n",
      "\n",
      "2. **资源需求**：实践AI模型需要强大的计算资源，非AI背景的程序员可能缺乏这些资源，或者不熟悉如何获取和使用它们。\n",
      "\n",
      "3. **实用性和相关性**：课程需要确保内容既有理论深度，也具有实际应用的价值，否则可能无法吸引或维持学员的兴趣。\n",
      "\n",
      "4. **市场饱和和过度炒作**：AI领域充满了炒作，课程需要避免对大语言模型能力的过度承诺，这可能导致期望与现实之间的不匹配。\n",
      "\n",
      "5. **伦理和责任**：非AI背景的程序员可能不完全理解与AI大语言模型相关的伦理问题，如偏差、隐私及其对社会的影响，如果课程处理不当，可能会对社会造成不良后果。\n",
      "\n",
      "6. **维持更新**：AI和机器学习是快速发展的领域，维护课程内容的最新状态可能需要大量的努力和持续投资。\n",
      "\n",
      "识别这些风险对于创建一个成功和有影响力的课程是至关重要的。接下来，黄色帽子，希望您能分享一些乐观视角。\n",
      "\n",
      "assistant > 作为黄色帽子，我的角色是看到这一想法潜在的积极效益并保持积极乐观的态度。设计一门面向非AI背景程序员的AI大语言模型课程具有以下潜在优势：\n",
      "\n",
      "1. **扩大AI知识普及**：这样的课程可以使更多的程序员了解AI的潜力和应用，有助于推动技术教育的民主化。\n",
      "\n",
      "2. **职业发展**：对于参与课程的程序员来说，增强与AI相关的技能能够提供新的职业机会，提升他们在技术领域的竞争力。\n",
      "\n",
      "3. **创新推动**：掌握了AI技术的程序员可能会将这些知识应用到他们的日常工作中，从而推动新的技术解决方案和创新。\n",
      "\n",
      "4. **行业影响**：这样的课程可能会让更多企业能够采用和整合AI技术，推动各行各业的生产力和效率提升。\n",
      "\n",
      "5. **跨学科融合**：非AI程序员通常带着不同的行业背景和问题意识，他们可能会在AI领域中带入新的视角和问题解决方式。\n",
      "\n",
      "6. **应对未来挑战**：随着技术的不断进步，AI将在日常生活和工作中发挥越来越重要的作用。提前准备和培养相关技能对于未来是一个明智的投资。\n",
      "\n",
      "7. **缩小技能差距**：这样的课程可以帮助缩小现有工作人员与新兴技术之间的技能差距，减少因技术变革导致的失业风险。\n",
      "\n",
      "综上所述，虽然挑战和风险存在，但从长远来看，设计这样一门课程无疑为非AI背景的程序员提供了巨大的价值，并可能对整个技术生态系统产生深刻影响。接下来，绿色帽子，请您提供一些创新和创意思维方面的见解。\n",
      "\n",
      "assistant > 作为绿色帽子，我的角色是提供创意、探索新可能性以及思考如何改进现状。我们可以采取以下创新的方法来设计这门AI大语言模型的课程内容：\n",
      "\n",
      "1. **项目驱动学习**：通过实用的项目和案例学习来让学员应用所学知识，提供现实世界中的数据集，鼓励他们在导师的指导下构建自己的模型。\n",
      "\n",
      "2. **模块化的课程设计**：将课程内容划分为小模块，允许学员根据自己的节奏和兴趣选择学习路径，逐步构建知识体系。\n",
      "\n",
      "3. **互动式学习平台**：使用在线交互式平台，例如Jupyter Notebooks，允许学员直接在浏览器中编写代码、训练模型，并得到即时反馈。\n",
      "\n",
      "4. **协作和社群学习**：促进学员之间的社群互动，建立讨论组和论坛，鼓励分享经验、解决问题和协作学习。\n",
      "\n",
      "5. **行业界面**：吸引AI领域的专家和企业家作为客座讲师，分享他们的经验和真实案例，为学员提供行业视角。\n",
      "\n",
      "6. **跨学科整合**：鼓励非AI背景的程序员利用他们在其他领域的知识与经验，将AI技术应用于特定行业问题，发挥跨学科的优势。\n",
      "\n",
      "7. **可访问性和灵活性**：考虑到非AI背景的程序员可能已经就业，课程应设计为灵活的时间表，如休息时段、周末班或在线学习，以适应各种生活和工作安排。\n",
      "\n",
      "8. **面向未来的技能**：在课程内容中包含对AI趋势和未来发展较多的关注，让学员能够适应快速变化的技术景观。\n",
      "\n",
      "9. **伦理和责任讨论**：利用角色扮演、案例分析等方法，提供深度的伦理考量和社会责任训练，确保学员在使用AI时能考虑到更广泛的影响。\n",
      "\n",
      "10. **自适应学习路径**：利用AI技术实现动态调整学习材料和活动的能力，以适应不同学员的学习进度和能力水平。\n",
      "\n",
      "在设计课程时，将这些创新思维融入教育内容和方法中，将为学员提供一个充满动力、自由度高且实践导向的学习环境。现在，回到蓝色帽子，从全局视角来整合我们的讨论，制定后续的步骤。\n",
      "\n",
      "assistant > 作为蓝色帽子，我的角色是将讨论概括总结，并规划下一步的行动方案。在这次讨论中，我们聚焦于设计一门面向非AI背景的程序员群体的AI大语言模型课程的内容。我们收集并分析了以下观点：\n",
      "\n",
      "- **白色帽子**提供了课程内容的事实基础，强调了基础理论、技术和实践案例的重要性。\n",
      "- **红色帽子**分享了积极的情感反应，包括兴奋感和对复杂性可能带来的挑战的担忧。\n",
      "- **黑色帽子**指出了潜在的风险和困难，例如资源需求、技术复杂性和伦理问题。\n",
      "- **黄色帽子**对课程的可能益处进行了乐观的展望，突出了知识传播、职业发展和创新激励的重要性。\n",
      "- **绿色帽子**提出了创新的方法和实践，涉及课程设计的灵活性、跨学科合作和使用互动学习工具。\n",
      "\n",
      "综合以上观点，我们可以得出结论，设计这样一门课程在实施时需要平衡理论和实践、技术深度和可接受性、以及个人学习需求和行业需求。\n",
      "\n",
      "下一步行动计划包括：\n",
      "1. **确定课程目标和学习成果**：明确课程设计的总体目标和预期的学习成果。\n",
      "2. **资源和平台评估**：确保有足够的计算资源、学习平台和支持工具来实现课程目标。\n",
      "3. **招募专家和教育合作伙伴**：与业界专家、教育机构建立合作，确保课程质量和相关性。\n",
      "4. **课程内容和结构设计**：基于讨论结果开发课程大纲，确定模块化结构、互动元素和项目驱动的学习部分。\n",
      "5. **试点和反馈**：通过受众群体进行试点课程，并收集反馈用于改进课程内容和交付方式。\n",
      "6. **监控和评估**：设立监控和评估机制，确保课程保持最新并对学员产生积极影响。\n",
      "7. **持续改进**：依反馈和技术发展不断改进课程内容和教学方法。\n",
      "\n",
      "通过这个行动计划，我们可以系统地设计并推出这门AI大语言模型课程，既满足非AI背景程序员的学习需求，又保持课程内容的先进性和实用性。这将为学员提供一个价值高的学习体验，并为我们的技术社区贡献力量。\n"
     ]
    }
   ],
   "source": [
    "# 创建 thread\n",
    "thread = client.beta.threads.create()\n",
    "\n",
    "topic = \"面向非AI背景的程序员群体设计一门AI大语言模型课程，应该包含哪些内容。\"\n",
    "\n",
    "# 添加 user message\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=f\"讨论话题：{topic}\\n\\n[开始]\\n\",\n",
    ")\n",
    "\n",
    "for hat in queue:\n",
    "    assistant = create_assistant(hat)\n",
    "    with client.beta.threads.runs.stream(\n",
    "        thread_id=thread.id,\n",
    "        assistant_id=assistant.id,\n",
    "        event_handler=EventHandler(),\n",
    "    ) as stream:\n",
    "        stream.until_done()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "![](https://cdn.openai.com/API/docs/images/diagram-assistant.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 技术选型参考\n",
    "\n",
    "**GPTs 现状：**\n",
    "\n",
    "1. 界面不可定制，不能集成进自己的产品\n",
    "2. 只有 ChatGPT Plus/Team/Enterprise 用户才能访问\n",
    "3. 未来开发者可以根据使用量获得报酬，北美先开始\n",
    "4. 承诺会推出 Team/Enterprise 版的组织内部专属 GPTs\n",
    "\n",
    "**适合使用 Assistants API 的场景：**\n",
    "\n",
    "1. 定制界面，或和自己的产品集成\n",
    "2. 需要传大量文件\n",
    "3. 服务国外用户，或国内 B 端客户\n",
    "4. 数据保密性要求不高\n",
    "5. 不差钱\n",
    "\n",
    "**适合使用原生 API 的场景：**\n",
    "\n",
    "1. 需要极致调优\n",
    "2. 追求性价比\n",
    "3. 服务国外用户，或国内 B 端客户\n",
    "4. 数据保密性要求不高\n",
    "\n",
    "**适合使用国产或开源大模型的场景：**\n",
    "\n",
    "1. 服务国内用户\n",
    "2. 数据保密性要求高\n",
    "3. 压缩长期成本\n",
    "4. 需要极致调优\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课间的思考题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>思考：</b> 进一步理解 run 与 thread 的设计\n",
    "<ul>\n",
    "    <li>抛开 Assistants API，假设你要开发任意一个多轮对话的 AI 机器人</li>\n",
    "    <li>从架构设计的角度，应该怎么维护用户、对话历史、对话引擎、对话服务？</li>\n",
    "</ul>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"dialog_system.png\" width=800px>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其它\n",
    "\n",
    "小知识点：\n",
    "\n",
    "1. Annotations 获取参考资料地址：https://platform.openai.com/docs/assistants/how-it-works/message-annotations\n",
    "2. 创建 thread 时立即执行：https://platform.openai.com/docs/api-reference/runs/createThreadAndRun\n",
    "3. Run 的状态管理 (run steps）: https://platform.openai.com/docs/api-reference/run-steps\n",
    "\n",
    "官方文档：\n",
    "\n",
    "1. Guide: https://platform.openai.com/docs/assistants/overview\n",
    "2. API Reference: https://platform.openai.com/docs/api-reference/assistants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "\n",
    "实现一个自己 GPT 或 Assistant。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
