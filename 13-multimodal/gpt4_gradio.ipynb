{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "374278d7",
   "metadata": {},
   "source": [
    "## GPT4v 实战：API 调用、使用场景实践\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b1b37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<b>注意：</b>\n",
    "<p>由于网络原因下面代码务必在自己的电脑上运行，才能看到界面</p>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2240c2a2",
   "metadata": {},
   "source": [
    "## 步骤 1：安装所需依赖的包\n",
    "\n",
    "确保你已经安装了 Python，并使用 pip 安装 Gradio, OpenAI, 以及 Gemini 所需依赖库：\n",
    "\n",
    "#### 如果在本地电脑执行下面命令\n",
    "\n",
    "```\n",
    "pip  install gradio openai google-generativeai\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c12c38",
   "metadata": {},
   "source": [
    "## 如果在实验室执行下面命令\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4145874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gradio==3.50 in /opt/conda/lib/python3.11/site-packages (3.50.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (23.2.1)\n",
      "Requirement already satisfied: altair<6.0,>=4.2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (5.2.0)\n",
      "Requirement already satisfied: fastapi in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.110.0)\n",
      "Requirement already satisfied: ffmpy in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.3.2)\n",
      "Requirement already satisfied: gradio-client==0.6.1 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.6.1)\n",
      "Requirement already satisfied: httpx in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.26.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.20.1)\n",
      "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (6.0.0)\n",
      "Requirement already satisfied: jinja2<4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (3.1.2)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (2.1.3)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (3.8.3)\n",
      "Requirement already satisfied: numpy~=1.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (1.26.2)\n",
      "Requirement already satisfied: orjson~=3.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (3.9.15)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (2.2.1)\n",
      "Requirement already satisfied: pillow<11.0,>=8.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (10.1.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (1.10.14)\n",
      "Requirement already satisfied: pydub in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.25.1)\n",
      "Requirement already satisfied: python-multipart in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.0.9)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (6.0.1)\n",
      "Requirement already satisfied: requests~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (2.31.0)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (2.10.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (4.10.0)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (0.27.1)\n",
      "Requirement already satisfied: websockets<12.0,>=10.0 in /opt/conda/lib/python3.11/site-packages (from gradio==3.50) (11.0.3)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from gradio-client==0.6.1->gradio==3.50) (2023.12.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50) (4.20.0)\n",
      "Requirement already satisfied: toolz in /opt/conda/lib/python3.11/site-packages (from altair<6.0,>=4.2.0->gradio==3.50) (0.12.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.50) (3.13.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.14.0->gradio==3.50) (4.65.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50) (4.49.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.11/site-packages (from matplotlib~=3.0->gradio==3.50) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==3.50) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas<3.0,>=1.0->gradio==3.50) (2024.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests~=2.0->gradio==3.50) (2023.11.17)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio==3.50) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.11/site-packages (from uvicorn>=0.14.0->gradio==3.50) (0.14.0)\n",
      "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /opt/conda/lib/python3.11/site-packages (from fastapi->gradio==3.50) (0.36.3)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.11/site-packages (from httpx->gradio==3.50) (3.7.1)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx->gradio==3.50) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from httpx->gradio==3.50) (1.3.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (2023.6.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (0.29.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50) (0.8.10)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio==3.50) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio==3.50  # 在实验室运行时执行的代码，本地不需要\n",
    "%pip install -q -U google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559039ff",
   "metadata": {},
   "source": [
    "下面代码创建了一个 Gradio 用户界面，可以在文本框中输入问题，并上传最多三张图像。\n",
    "这些输入将传递给 query_gpt4_vision 函数，该函数使用 OpenAI GPT-4 Vision 模型生成对问题的回答。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a45cbb7",
   "metadata": {},
   "source": [
    "## 步骤 2：编写 Gradio 与 GPT-4 Vision 应用\n",
    "\n",
    "在你的 Python 脚本中，编写 Gradio 应用。以下是一个例子，使用 GPT-4 Vision 模型：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6f61f40-d846-46a7-b7ab-d31b2fd2f588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyBT4YQP0Cx_STdRFHUx05SfXtcB5zHz4gc\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "googleapi_key = os.getenv('GOOGLE_API_KEY')\n",
    "print(googleapi_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55b5749e-2180-4575-921a-480e0f1b029f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "Running on public URL: https://347a5ce7a5bf3da805.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://347a5ce7a5bf3da805.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Function to encode the image to base64\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to query GPT-4 Vision\n",
    "\n",
    "\n",
    "def query_gpt4_vision(text, image1, image2, image3):\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    messages = [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": text}]}]\n",
    "\n",
    "    images = [image1, image2, image3]\n",
    "    for image in images:\n",
    "        if image is not None:\n",
    "            base64_image = encode_image_to_base64(image)\n",
    "            image_message = {\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            }\n",
    "            messages[0][\"content\"].append(image_message)\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to query Gemini-Pro\n",
    "\n",
    "\n",
    "def query_gemini_vision(text, image1, image2, image3):\n",
    "    # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "    # GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro-vision')\n",
    "\n",
    "    images = [image1, image2, image3]\n",
    "    query = [text]\n",
    "    for image in images:\n",
    "        if image is not None:\n",
    "            query.append(image)\n",
    "    response = model.generate_content(query, stream=False)\n",
    "    response.resolve()\n",
    "\n",
    "    return response.text\n",
    "\n",
    "# 由于Gradio 2.0及以上版本的界面构建方式有所不同，这里使用blocks API来创建更复杂的UI\n",
    "\n",
    "\n",
    "def main():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"### 输入文本\")\n",
    "        input_text = gr.Textbox(lines=2, label=\"输入文本\")\n",
    "        input_images = [\n",
    "            gr.Image(type=\"pil\", label=\"Upload Image\", tool=\"editor\") for i in range(3)]\n",
    "        output_gpt4 = gr.Textbox(label=\"GPT-4 输出\")\n",
    "        output_other_api = gr.Textbox(label=\"Gemini-Pro 输出\")\n",
    "        btn_gpt4 = gr.Button(\"调用GPT-4\")\n",
    "        btn_other_api = gr.Button(\"调用Gemini-Pro\")\n",
    "\n",
    "        btn_gpt4.click(fn=query_gpt4_vision, inputs=[\n",
    "                       input_text] + input_images, outputs=output_gpt4)\n",
    "        btn_other_api.click(fn=query_gemini_vision, inputs=[\n",
    "                            input_text] + input_images, outputs=output_other_api)\n",
    "\n",
    "    demo.launch(share=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba8a19c",
   "metadata": {},
   "source": [
    "## 步骤 3：运行 Gradio 应用\n",
    "\n",
    "保存并运行你的 Python 脚本。这将启动 Gradio 用户界面，并在终端中显示本地运行的 URL（通常是 http://127.0.0.1:7860）。访问该 URL 即可查看和使用你的 Gradio 应用。\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "<b>建议：</b>\n",
    "<li>确保你的机器上已经安装了必要的 Python 包。</li>\n",
    "<li> 如果使用 OpenAI 模型，确保你已经设置了正确的 API 密钥。 </li>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d35267",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8063afad-6b39-4a67-8885-57931e7236a8",
   "metadata": {},
   "source": [
    "## Examples\n",
    "\n",
    "- 菜品价格预估：估算一下这桌子菜的价格，给出每道菜的市场价格。假设这是北京的一家中档餐厅\n",
    "- figure 理解：请生成这张图片的 caption\n",
    "- 网页设计：生成下面设计图对应的网站源码\n",
    "- 视觉结合知识的推断：根据图中信息，猜测这是什么型号的 GPU？请列出所有可能的 GPU 型号，并给出你的判断依据。猜测大致的生产年限\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5daeb844-eb3d-409b-8be6-f23de1267e1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7864\n",
      "Running on public URL: https://0ecfbc1d19c19a7443.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://0ecfbc1d19c19a7443.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from PIL import Image\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Function to encode the image to base64\n",
    "\n",
    "\n",
    "def encode_image_to_base64(image):\n",
    "    buffered = io.BytesIO()\n",
    "    image.save(buffered, format=\"JPEG\")\n",
    "    return base64.b64encode(buffered.getvalue()).decode('utf-8')\n",
    "\n",
    "# Function to query GPT-4 Vision\n",
    "\n",
    "\n",
    "def query_gpt4_vision(*inputs):\n",
    "    client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    messages = [{\"role\": \"user\", \"content\": []}]\n",
    "\n",
    "    for input_item in inputs:\n",
    "        if isinstance(input_item, str):  # Text input\n",
    "            messages[0][\"content\"].append({\"type\": \"text\", \"text\": input_item})\n",
    "        elif isinstance(input_item, Image.Image):  # Image input\n",
    "            base64_image = encode_image_to_base64(input_item)\n",
    "            messages[0][\"content\"].append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}\n",
    "            })\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-vision-preview\",\n",
    "        messages=messages,\n",
    "        max_tokens=1024,\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# Function to query Gemini-Pro\n",
    "\n",
    "\n",
    "def query_gemini_vision(*inputs):\n",
    "    # Or use `os.getenv('GOOGLE_API_KEY')` to fetch an environment variable.\n",
    "    # GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
    "    GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "    # print(GOOGLE_API_KEY)\n",
    "    genai.configure(api_key=GOOGLE_API_KEY)\n",
    "    model = genai.GenerativeModel('gemini-pro-vision')\n",
    "\n",
    "    query = []\n",
    "    for item in inputs:\n",
    "        if item is not None:\n",
    "            query.append(item)\n",
    "    response = model.generate_content(query, stream=False)\n",
    "    response.resolve()\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "'''\n",
    "    \n",
    "# Dynamically generate input components\n",
    "input_components = []\n",
    "for i in range(2):  # Change this number to add more inputs\n",
    "    input_components.append(gr.components.Textbox(lines=2, placeholder=f\"Enter your text input {i+1}...\"))\n",
    "    input_components.append(gr.components.Image(type=\"pil\", label=f\"Upload Image {i+1}\", tool=\"editor\"))\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=query_gpt4_vision,\n",
    "    inputs=input_components,\n",
    "    outputs=gr.components.Text(update=True), \n",
    ")\n",
    "\n",
    "iface.launch(share=True)\n",
    "\n",
    "'''\n",
    "\n",
    "# 由于Gradio 2.0及以上版本的界面构建方式有所不同，这里使用blocks API来创建更复杂的UI\n",
    "\n",
    "\n",
    "def main():\n",
    "    with gr.Blocks() as demo:\n",
    "        gr.Markdown(\"### 输入文本\")\n",
    "        # input_text = gr.Textbox(lines=2, label=\"输入文本\")\n",
    "        input_components = []\n",
    "        for i in range(2):  # Change this number to add more inputs\n",
    "            input_components.append(gr.Textbox(\n",
    "                lines=2, placeholder=f\"Enter your text input {i+1}...\"))\n",
    "            input_components.append(\n",
    "                gr.Image(type=\"pil\", label=f\"Upload Image {i+1}\", tool=\"editor\"))\n",
    "\n",
    "        # input_images = [gr.Image(type=\"pil\", label=\"Upload Image\", tool=\"editor\") for i in range(3)]\n",
    "        output_gpt4 = gr.Textbox(label=\"GPT-4 输出\")\n",
    "        output_other_api = gr.Textbox(label=\"Gemini-Pro 输出\")\n",
    "        btn_gpt4 = gr.Button(\"调用GPT-4\")\n",
    "        btn_other_api = gr.Button(\"调用Gemini-Pro\")\n",
    "\n",
    "        btn_gpt4.click(fn=query_gpt4_vision,\n",
    "                       inputs=input_components, outputs=output_gpt4)\n",
    "        btn_other_api.click(fn=query_gemini_vision,\n",
    "                            inputs=input_components, outputs=output_other_api)\n",
    "\n",
    "    demo.launch(share=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc09939-2aaa-456a-ada6-ac8c69b33cdd",
   "metadata": {},
   "source": [
    "- 具身智能场景：\n",
    "  假设你是一个机器人，在厨房从事工作，你会执行的操作包括 靠近(物体坐标)， 抓取(物体坐标), 移动(开始坐标，结束坐标)，这里的坐标需要根据你的视觉系统来估计 xy 位置，以及深度信息 z。人类会给你指令，你需要按照人类指令要求的完成对应的操作。比如，人类：把抽屉里的绿色包装袋拿出来。此时你看到的画面是这样的：\n",
    "  请问接下来你该执行什么指令？只给出指令即可，但是需要包括具体的坐标信息（假设当前画面的长宽为单位 1，使用你估计的深度信息以及 xy 偏移位置）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00320ab-8cb2-4dae-8646-31fb095d9ee3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95875cc-1969-4e8b-9dfd-74629010da00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
